{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac300a127214411f800d3f2e63e6ea12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9e386f03f714a6a80587987f3c451e9",
              "IPY_MODEL_8848db3547f6435a817ab8f2c9b3020e",
              "IPY_MODEL_a205075e3006414f974ebed91cea86f9",
              "IPY_MODEL_8ae9afc80a4a4cda9190d9901e23b354"
            ],
            "layout": "IPY_MODEL_65dacc0c32d441b99abfdb5fc6cb45b4"
          }
        },
        "c1a8742e602a42e8831b8811e9b73184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b20c49f25ac44c69a98add685e95ae1",
            "placeholder": "​",
            "style": "IPY_MODEL_f3c5cb6955a845878085d93e56f38ed7",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ff24049ebc7d478da81ad5f80cf0e2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1584ba6714084eb7b9f7b514bb1f5f02",
            "placeholder": "​",
            "style": "IPY_MODEL_7eceb6680fb24372b46eeed9085e5583",
            "value": ""
          }
        },
        "9aa883ab86404c298ce0174fa7914902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_e1ed4c69ff984d3b8058e9976fbd28fc",
            "style": "IPY_MODEL_afed1ec999fb4cc4afb5a0a308c41524",
            "value": true
          }
        },
        "945776f72f3942f3af92a1e54f30d81f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_21a7aa5d640c477480075be0b99473a7",
            "style": "IPY_MODEL_e1309a9ca29145e1a26652260adf9c63",
            "tooltip": ""
          }
        },
        "eb04367012c649ecb327cac7169b719b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43eef80aed0543aa88ef351169ad6ad8",
            "placeholder": "​",
            "style": "IPY_MODEL_68b7764aacb74f4598fdfb6bbd9ef1de",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "65dacc0c32d441b99abfdb5fc6cb45b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "0b20c49f25ac44c69a98add685e95ae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c5cb6955a845878085d93e56f38ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1584ba6714084eb7b9f7b514bb1f5f02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eceb6680fb24372b46eeed9085e5583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1ed4c69ff984d3b8058e9976fbd28fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afed1ec999fb4cc4afb5a0a308c41524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21a7aa5d640c477480075be0b99473a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1309a9ca29145e1a26652260adf9c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "43eef80aed0543aa88ef351169ad6ad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68b7764aacb74f4598fdfb6bbd9ef1de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fab6f98d397448559be8c306a7208faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63659eb12d5d422baab9a483eb72f322",
            "placeholder": "​",
            "style": "IPY_MODEL_8b710ed2f0504dd4818c3a8a2a033bc8",
            "value": "Connecting..."
          }
        },
        "63659eb12d5d422baab9a483eb72f322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b710ed2f0504dd4818c3a8a2a033bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9e386f03f714a6a80587987f3c451e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26387b0e7d084ffba3432345e4bfcf95",
            "placeholder": "​",
            "style": "IPY_MODEL_ee72389a9e764ecb9daf22025d6f1739",
            "value": "Token is valid (permission: write)."
          }
        },
        "8848db3547f6435a817ab8f2c9b3020e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_638c39887f654c3698ab7130626c2b3d",
            "placeholder": "​",
            "style": "IPY_MODEL_5558c9e4fe33458bb342e383bc64e4ca",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "a205075e3006414f974ebed91cea86f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d13e2779d1554dd38d81f948e66cc5ce",
            "placeholder": "​",
            "style": "IPY_MODEL_d73a18894bf24642b651936aaf65f113",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "8ae9afc80a4a4cda9190d9901e23b354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a745a74189f435c8138bca0da1fbfa4",
            "placeholder": "​",
            "style": "IPY_MODEL_eb74c7e10d8c4ce380cd846ca89a7572",
            "value": "Login successful"
          }
        },
        "26387b0e7d084ffba3432345e4bfcf95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee72389a9e764ecb9daf22025d6f1739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "638c39887f654c3698ab7130626c2b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5558c9e4fe33458bb342e383bc64e4ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d13e2779d1554dd38d81f948e66cc5ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d73a18894bf24642b651936aaf65f113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a745a74189f435c8138bca0da1fbfa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb74c7e10d8c4ce380cd846ca89a7572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3299551291fe4e809020fb0905e55a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19336c5be4ba4961a015a44b6e2ffa56",
              "IPY_MODEL_bd8dcfee3aae45b2af189ffba646203b",
              "IPY_MODEL_3ac933ecafff4e898b702209602f3320"
            ],
            "layout": "IPY_MODEL_1aabb841a5e04e1c96ca0bb79fd05783"
          }
        },
        "19336c5be4ba4961a015a44b6e2ffa56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3760abb046e84624929007f4ee2138ad",
            "placeholder": "​",
            "style": "IPY_MODEL_95ccab2415cd43f4b2e632a27830195b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "bd8dcfee3aae45b2af189ffba646203b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_862fa77b1df546d2b90c0684e6b87f59",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3246d0ca16eb44dea22ca9b0e16100b8",
            "value": 48
          }
        },
        "3ac933ecafff4e898b702209602f3320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_454a63e2225640c0a7e831203d436642",
            "placeholder": "​",
            "style": "IPY_MODEL_167d665a47484b59878ca866ca90400e",
            "value": " 48.0/48.0 [00:00&lt;00:00, 976B/s]"
          }
        },
        "1aabb841a5e04e1c96ca0bb79fd05783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3760abb046e84624929007f4ee2138ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95ccab2415cd43f4b2e632a27830195b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "862fa77b1df546d2b90c0684e6b87f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3246d0ca16eb44dea22ca9b0e16100b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "454a63e2225640c0a7e831203d436642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "167d665a47484b59878ca866ca90400e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9ea8f46193b4f7ea6451053da9021d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc1968538f3a48ebbb7623368de7a22c",
              "IPY_MODEL_33ee68b5a83b46f98e8c11c92685b151",
              "IPY_MODEL_17e1339bed3c487c8aa0ee0325fe05d7"
            ],
            "layout": "IPY_MODEL_e24f494fdb9346a691fba266808da4ab"
          }
        },
        "bc1968538f3a48ebbb7623368de7a22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe2572d138c849ac9dfed18747510157",
            "placeholder": "​",
            "style": "IPY_MODEL_2121d2a0c7fc4cd4a97646198b57de6c",
            "value": "vocab.txt: 100%"
          }
        },
        "33ee68b5a83b46f98e8c11c92685b151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9809348ba88a47f5a9a069046bd1e846",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54355c84242446bb9b9d6a7da49be884",
            "value": 231508
          }
        },
        "17e1339bed3c487c8aa0ee0325fe05d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3beeb593d8b4af4bd30276db3e70713",
            "placeholder": "​",
            "style": "IPY_MODEL_d93ddd18bd4d4aada84f17aed57ffed2",
            "value": " 232k/232k [00:00&lt;00:00, 1.76MB/s]"
          }
        },
        "e24f494fdb9346a691fba266808da4ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe2572d138c849ac9dfed18747510157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2121d2a0c7fc4cd4a97646198b57de6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9809348ba88a47f5a9a069046bd1e846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54355c84242446bb9b9d6a7da49be884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3beeb593d8b4af4bd30276db3e70713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d93ddd18bd4d4aada84f17aed57ffed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69c572f547ab471bb01d87898ee85c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8b8bc126b5f40b3bdcb7e76ecb6b308",
              "IPY_MODEL_43b7ae2e1d4749eaa900732b7d00ead5",
              "IPY_MODEL_fd8ec3f4422a4c5e891fc78368197f22"
            ],
            "layout": "IPY_MODEL_1c9dd2dc32ef46b68c3eaeb8bcecf40b"
          }
        },
        "d8b8bc126b5f40b3bdcb7e76ecb6b308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6889fd1bf25e4ad89f340781dcfaca1e",
            "placeholder": "​",
            "style": "IPY_MODEL_57476849500a4ab7854935be052844c7",
            "value": "tokenizer.json: 100%"
          }
        },
        "43b7ae2e1d4749eaa900732b7d00ead5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53e1c005c96b4ee383417adba744821d",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_894ac0a95b0443e8921b1f258613a8c2",
            "value": 466062
          }
        },
        "fd8ec3f4422a4c5e891fc78368197f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1da1a652f9941a59fed12b0b9eb9368",
            "placeholder": "​",
            "style": "IPY_MODEL_2ef79568d5a24778b8abafbb94562f76",
            "value": " 466k/466k [00:00&lt;00:00, 2.32MB/s]"
          }
        },
        "1c9dd2dc32ef46b68c3eaeb8bcecf40b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6889fd1bf25e4ad89f340781dcfaca1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57476849500a4ab7854935be052844c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53e1c005c96b4ee383417adba744821d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "894ac0a95b0443e8921b1f258613a8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1da1a652f9941a59fed12b0b9eb9368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ef79568d5a24778b8abafbb94562f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94044d67170543b3b4483216ef2c01cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d655e24bbbb742bebfda8366407c01e2",
              "IPY_MODEL_21862fe72e6948d28a77966a0a99c7bd",
              "IPY_MODEL_1a267d53a657408982515e2763c64932"
            ],
            "layout": "IPY_MODEL_e97c7f60c39e44ceb0a96ceb8e9d5e78"
          }
        },
        "d655e24bbbb742bebfda8366407c01e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73bd054d1a9b42a1b27353bcdd8f40f4",
            "placeholder": "​",
            "style": "IPY_MODEL_cfde0409057e4f6396378b7f546ce6c5",
            "value": "config.json: 100%"
          }
        },
        "21862fe72e6948d28a77966a0a99c7bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2edfdb2a1694552997235d107e98386",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3762f93f124a4ddfac12f6bbb476de22",
            "value": 570
          }
        },
        "1a267d53a657408982515e2763c64932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_041d5a5e3eba4e2d9c0e5d53fc99b5d6",
            "placeholder": "​",
            "style": "IPY_MODEL_0b716c57731b46d7949428d6f5b9be7f",
            "value": " 570/570 [00:00&lt;00:00, 19.3kB/s]"
          }
        },
        "e97c7f60c39e44ceb0a96ceb8e9d5e78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73bd054d1a9b42a1b27353bcdd8f40f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfde0409057e4f6396378b7f546ce6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2edfdb2a1694552997235d107e98386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3762f93f124a4ddfac12f6bbb476de22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "041d5a5e3eba4e2d9c0e5d53fc99b5d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b716c57731b46d7949428d6f5b9be7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hb75xlYZiYW",
        "outputId": "8e30d6a8-c6b5-4a3b-eca8-0aabd2475815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision\n",
        "\n",
        "\n",
        "# General\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Device Setting\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  print(\"GPU\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "ac300a127214411f800d3f2e63e6ea12",
            "c1a8742e602a42e8831b8811e9b73184",
            "ff24049ebc7d478da81ad5f80cf0e2a3",
            "9aa883ab86404c298ce0174fa7914902",
            "945776f72f3942f3af92a1e54f30d81f",
            "eb04367012c649ecb327cac7169b719b",
            "65dacc0c32d441b99abfdb5fc6cb45b4",
            "0b20c49f25ac44c69a98add685e95ae1",
            "f3c5cb6955a845878085d93e56f38ed7",
            "1584ba6714084eb7b9f7b514bb1f5f02",
            "7eceb6680fb24372b46eeed9085e5583",
            "e1ed4c69ff984d3b8058e9976fbd28fc",
            "afed1ec999fb4cc4afb5a0a308c41524",
            "21a7aa5d640c477480075be0b99473a7",
            "e1309a9ca29145e1a26652260adf9c63",
            "43eef80aed0543aa88ef351169ad6ad8",
            "68b7764aacb74f4598fdfb6bbd9ef1de",
            "fab6f98d397448559be8c306a7208faf",
            "63659eb12d5d422baab9a483eb72f322",
            "8b710ed2f0504dd4818c3a8a2a033bc8",
            "d9e386f03f714a6a80587987f3c451e9",
            "8848db3547f6435a817ab8f2c9b3020e",
            "a205075e3006414f974ebed91cea86f9",
            "8ae9afc80a4a4cda9190d9901e23b354",
            "26387b0e7d084ffba3432345e4bfcf95",
            "ee72389a9e764ecb9daf22025d6f1739",
            "638c39887f654c3698ab7130626c2b3d",
            "5558c9e4fe33458bb342e383bc64e4ca",
            "d13e2779d1554dd38d81f948e66cc5ce",
            "d73a18894bf24642b651936aaf65f113",
            "3a745a74189f435c8138bca0da1fbfa4",
            "eb74c7e10d8c4ce380cd846ca89a7572"
          ]
        },
        "id": "fTJDKrnsZkUT",
        "outputId": "bde9426a-7725-4789-f8ef-e662ef5545cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac300a127214411f800d3f2e63e6ea12"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets tokenizers\n",
        "\n",
        "# Huggingface\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from transformers import BertTokenizer\n",
        "from datasets import load_dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Lz6N4-KZtDe",
        "outputId": "8296d1ff-6fea-45cd-a5de-669d97f7dceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/510.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/510.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert Tokenizer"
      ],
      "metadata": {
        "id": "KXxT67GKac8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "vocab_size = tokenizer.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "3299551291fe4e809020fb0905e55a2c",
            "19336c5be4ba4961a015a44b6e2ffa56",
            "bd8dcfee3aae45b2af189ffba646203b",
            "3ac933ecafff4e898b702209602f3320",
            "1aabb841a5e04e1c96ca0bb79fd05783",
            "3760abb046e84624929007f4ee2138ad",
            "95ccab2415cd43f4b2e632a27830195b",
            "862fa77b1df546d2b90c0684e6b87f59",
            "3246d0ca16eb44dea22ca9b0e16100b8",
            "454a63e2225640c0a7e831203d436642",
            "167d665a47484b59878ca866ca90400e",
            "a9ea8f46193b4f7ea6451053da9021d8",
            "bc1968538f3a48ebbb7623368de7a22c",
            "33ee68b5a83b46f98e8c11c92685b151",
            "17e1339bed3c487c8aa0ee0325fe05d7",
            "e24f494fdb9346a691fba266808da4ab",
            "fe2572d138c849ac9dfed18747510157",
            "2121d2a0c7fc4cd4a97646198b57de6c",
            "9809348ba88a47f5a9a069046bd1e846",
            "54355c84242446bb9b9d6a7da49be884",
            "f3beeb593d8b4af4bd30276db3e70713",
            "d93ddd18bd4d4aada84f17aed57ffed2",
            "69c572f547ab471bb01d87898ee85c99",
            "d8b8bc126b5f40b3bdcb7e76ecb6b308",
            "43b7ae2e1d4749eaa900732b7d00ead5",
            "fd8ec3f4422a4c5e891fc78368197f22",
            "1c9dd2dc32ef46b68c3eaeb8bcecf40b",
            "6889fd1bf25e4ad89f340781dcfaca1e",
            "57476849500a4ab7854935be052844c7",
            "53e1c005c96b4ee383417adba744821d",
            "894ac0a95b0443e8921b1f258613a8c2",
            "e1da1a652f9941a59fed12b0b9eb9368",
            "2ef79568d5a24778b8abafbb94562f76",
            "94044d67170543b3b4483216ef2c01cf",
            "d655e24bbbb742bebfda8366407c01e2",
            "21862fe72e6948d28a77966a0a99c7bd",
            "1a267d53a657408982515e2763c64932",
            "e97c7f60c39e44ceb0a96ceb8e9d5e78",
            "73bd054d1a9b42a1b27353bcdd8f40f4",
            "cfde0409057e4f6396378b7f546ce6c5",
            "f2edfdb2a1694552997235d107e98386",
            "3762f93f124a4ddfac12f6bbb476de22",
            "041d5a5e3eba4e2d9c0e5d53fc99b5d6",
            "0b716c57731b46d7949428d6f5b9be7f"
          ]
        },
        "id": "z0UHNXy3aeqx",
        "outputId": "efd3380d-b56c-4a93-903d-b0e3f9646204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3299551291fe4e809020fb0905e55a2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9ea8f46193b4f7ea6451053da9021d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69c572f547ab471bb01d87898ee85c99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94044d67170543b3b4483216ef2c01cf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "gxarSfvcaKDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_config(num_epochs, vocab_size):\n",
        "  return{\n",
        "      \"train_batch_size\": 8,\n",
        "      \"test_batch_size\": 1,\n",
        "      \"num_epochs\": num_epochs,\n",
        "      \"lr\": 3e-4,\n",
        "      \"lang_src\": 'en',\n",
        "      \"lang_tgt\": 'fr',\n",
        "      \"seq_len\": 256,\n",
        "      \"d_model\": 256,\n",
        "      \"h\": 2,\n",
        "      \"depth\" : 1,\n",
        "      \"dropout\": 0.2,\n",
        "      \"num_classes\": vocab_size\n",
        "      }\n",
        "\n",
        "config = get_config(num_epochs=10, vocab_size=50265)\n"
      ],
      "metadata": {
        "id": "6X9MAIFNaJcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "4KSswLigbGLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset = load_dataset('opus_books', f'{config[\"lang_src\"]}-{config[\"lang_tgt\"]}', split='train')\n",
        "\n",
        "train_size = int(0.2 * len(raw_dataset))\n",
        "val_size = len(raw_dataset) - train_size\n",
        "train, val = random_split(raw_dataset, [train_size, val_size])\n",
        "\n"
      ],
      "metadata": {
        "id": "dSGaPVClZ3eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class BilingualDataset(Dataset):\n",
        "  def __init__(self, data, src_tokenizer, tgt_tokenizer, config):\n",
        "    super().__init__()\n",
        "\n",
        "    self.data = data\n",
        "    self.src_tokenizer = src_tokenizer\n",
        "    self.tgt_tokenizer = tgt_tokenizer\n",
        "\n",
        "    self.src_lang = config['lang_src']\n",
        "    self.tgt_lang = config['lang_tgt']\n",
        "\n",
        "    self.seq_len = config['seq_len']\n",
        "    self.h = config['h']\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    pairs = self.data[idx]\n",
        "\n",
        "    source = pairs['translation'][self.src_lang]\n",
        "    target = pairs['translation'][self.tgt_lang]\n",
        "\n",
        "    h = self.h\n",
        "    seq_len = self.seq_len\n",
        "\n",
        "    # tokenized_source\n",
        "    tokenized_source = self.src_tokenizer(source,\n",
        "                                     max_length = self.seq_len,\n",
        "                                     padding='max_length',\n",
        "                                     truncation = True\n",
        "                                     )\n",
        "\n",
        "    # source ids\n",
        "    source_ids = torch.tensor(tokenized_source['input_ids'], dtype= torch.long)\n",
        "\n",
        "    # source masks\n",
        "    source_masks = torch.tensor(tokenized_source['attention_mask'], dtype= torch.long).unsqueeze(0)\n",
        "    source_masks = source_masks.repeat(1, h, 1)\n",
        "    source_masks = source_masks.expand(seq_len, h, seq_len)\n",
        "    source_masks = source_masks.transpose(0,1).contiguous()\n",
        "\n",
        "    # tokenized_target\n",
        "    tokenized_target = self.tgt_tokenizer(target,\n",
        "                                     max_length = self.seq_len,\n",
        "                                     padding='max_length',\n",
        "                                     truncation = True\n",
        "                                     )\n",
        "\n",
        "    # target ids\n",
        "    target_ids = torch.tensor(tokenized_target['input_ids'], dtype= torch.long)\n",
        "\n",
        "    # target_masks\n",
        "    target_masks = torch.tensor(tokenized_target['attention_mask'], dtype= torch.long).unsqueeze(0)\n",
        "    target_masks = target_masks.repeat(1, h, 1)\n",
        "    target_masks = target_masks.expand(seq_len, h, seq_len)\n",
        "    target_masks = target_masks.transpose(0,1).contiguous().type(torch.int)\n",
        "    # target_masks must be causally masked\n",
        "    target_masks = target_masks & torch.tril(torch.ones(h, seq_len, seq_len)).type(torch.int)\n",
        "\n",
        "    item = {\n",
        "          'source_txt': source,\n",
        "          'target_txt': target,\n",
        "          'source_ids': source_ids,\n",
        "          'source_masks': source_masks,\n",
        "          'target_ids': target_ids,\n",
        "          'target_masks': target_masks\n",
        "    }\n",
        "\n",
        "    return item"
      ],
      "metadata": {
        "id": "wm-1lCODbCew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = get_config(1, vocab_size)\n",
        "\n",
        "src_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "tgt_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#  def __init__(self, data, src_tokenizer, tgt_tokenizer, config):\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    BilingualDataset(train, src_tokenizer, tgt_tokenizer, config),\n",
        "    batch_size = config['train_batch_size'],\n",
        "    shuffle=True,\n",
        "    pin_memory = True\n",
        ")\n",
        "\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    BilingualDataset(val, src_tokenizer, tgt_tokenizer, config),\n",
        "    batch_size = config['test_batch_size'],\n",
        "    shuffle=True,\n",
        "    pin_memory = True\n",
        ")\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "batch = next(dataiter)\n",
        "\n",
        "for idx in range(len(batch['source_ids'])):\n",
        "  print(f\"source text: {batch['source_txt'][idx]}\")\n",
        "  print(f\"target text: {batch['target_txt'][idx]}\")\n",
        "  print(f\"source ids: {batch['source_ids'][idx]}\")\n",
        "  print(f\"source masks: {batch['source_masks'].size()}\")\n",
        "  print(f\"target ids: {batch['target_ids'][idx]}\")\n",
        "  print(f\"target masks: {batch['target_masks'].size()}\")\n",
        "\n",
        "\n",
        "dataiter = iter(val_loader)\n",
        "batch = next(dataiter)\n",
        "\n",
        "for idx in range(len(batch['source_ids'])):\n",
        "  print(f\"source text: {batch['source_txt'][idx]}\")\n",
        "  print(f\"target text: {batch['target_txt'][idx]}\")\n",
        "  print(f\"source ids: {batch['source_ids'][idx]}\")\n",
        "  print(f\"source masks: {batch['source_masks'].size()}\")\n",
        "  print(f\"target ids: {batch['target_ids'][idx]}\")\n",
        "  print(f\"target masks: {batch['target_masks'].size()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OV8-fXQbHuf",
        "outputId": "56b099f2-d266-4202-ab29-e38a2951abb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source text: 'In reality, that is my husband,' she said to herself; 'if I return in sincerity to the standards of prudence, it is obviously he that I ought to marry.'\n",
            "target text: Au vrai, c’est là mon mari, se dit-elle ; si je reviens de bonne foi aux idées de sagesse, c’est évidemment lui que je dois épouser.\n",
            "source ids: tensor([  101,  1005,  1999,  4507,  1010,  2008,  2003,  2026,  3129,  1010,\n",
            "         1005,  2016,  2056,  2000,  2841,  1025,  1005,  2065,  1045,  2709,\n",
            "         1999, 23997,  2000,  1996,  4781,  1997, 10975, 29424,  1010,  2009,\n",
            "         2003,  5525,  2002,  2008,  1045, 11276,  2000,  5914,  1012,  1005,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "source masks: torch.Size([8, 2, 256, 256])\n",
            "target ids: tensor([  101,  8740, 27830,  4886,  1010,  1039,  1521,  9765,  2474, 12256,\n",
            "        16266,  1010,  7367,  4487,  2102,  1011, 15317,  1025,  9033, 15333,\n",
            "         7065, 24836,  2139, 19349,  2063,  1042, 10448, 19554,  8909, 10285,\n",
            "         2139, 10878, 11393,  1010,  1039,  1521,  9765, 23408,  5178, 20058,\n",
            "         3372, 11320,  2072, 10861, 15333,  9193,  2015,  4958, 15441,  2099,\n",
            "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "target masks: torch.Size([8, 2, 256, 256])\n",
            "source text: 'Do you know Conte Altamira?' she asked M. de Croisenois.\n",
            "target text: – Connaissez-vous le comte Altamira ? dit-elle à M. de Croisenois.\n",
            "source ids: tensor([  101,  1005,  2079,  2017,  2113,  9530,  2618, 23647, 14503,  2050,\n",
            "         1029,  1005,  2016,  2356,  1049,  1012,  2139, 13675, 23565,  3630,\n",
            "         2483,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "source masks: torch.Size([8, 2, 256, 256])\n",
            "target ids: tensor([  101,  1516,  9530, 28020,  3366,  2480,  1011, 29536,  2271,  3393,\n",
            "        19758, 23647, 14503,  2050,  1029,  4487,  2102,  1011, 15317,  1037,\n",
            "         1049,  1012,  2139, 13675, 23565,  3630,  2483,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "target masks: torch.Size([8, 2, 256, 256])\n",
            "source text: Had I used half as much prudence to have looked into my own interest, and have made a judgment of what I ought to have done and not to have done, I had certainly never gone away from so prosperous an undertaking, leaving all the probable views of a thriving circumstance, and gone upon a voyage to sea, attended with all its common hazards, to say nothing of the reasons I had to expect particular misfortunes to myself.\n",
            "target text: Si j'avais usé de moitié autant de prudence à considérer mon propre intérêt, et à me former un jugement de ce que je devais faire ou ne pas faire, je ne me serais certainement jamais éloigné d'une entreprise aussi florissante; je n'aurais point abandonné toutes les chances probables de m'enrichir, pour un voyage sur mer où je serais exposé à touts les hasards communs; pour ne rien dire des raisons que j'avais de m'attendre à des infortunes personnelles.\n",
            "source ids: tensor([  101,  2018,  1045,  2109,  2431,  2004,  2172, 10975, 29424,  2000,\n",
            "         2031,  2246,  2046,  2026,  2219,  3037,  1010,  1998,  2031,  2081,\n",
            "         1037,  8689,  1997,  2054,  1045, 11276,  2000,  2031,  2589,  1998,\n",
            "         2025,  2000,  2031,  2589,  1010,  1045,  2018,  5121,  2196,  2908,\n",
            "         2185,  2013,  2061, 18241,  2019, 18457,  1010,  2975,  2035,  1996,\n",
            "        15596,  5328,  1997,  1037, 20319, 25652,  1010,  1998,  2908,  2588,\n",
            "         1037,  8774,  2000,  2712,  1010,  3230,  2007,  2035,  2049,  2691,\n",
            "        22010,  1010,  2000,  2360,  2498,  1997,  1996,  4436,  1045,  2018,\n",
            "         2000,  5987,  3327, 28616, 13028, 26639,  2000,  2870,  1012,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "source masks: torch.Size([8, 2, 256, 256])\n",
            "target ids: tensor([  101,  9033,  1046,  1005, 10927,  2483,  2224,  2139, 25175,  9515,\n",
            "         8740,  5794,  2102,  2139, 10975, 29424,  1037,  5136,  2121, 12256,\n",
            "        17678,  2890,  6970,  3388,  1010,  3802,  1037,  2033,  2280,  4895,\n",
            "        26536, 13665,  2139,  8292, 10861, 15333, 16475, 15593,  4189,  2063,\n",
            "        15068, 11265, 14674,  4189,  2063,  1010, 15333, 11265,  2033, 26358,\n",
            "         2483,  3056, 13665,  9389, 15593,  3449, 10448, 10177,  1040,  1005,\n",
            "        16655,  4372,  7913, 18098,  5562, 17151,  5332, 13109, 21239, 22341,\n",
            "         2063,  1025, 15333,  1050,  1005, 15240,  2483,  2391, 10824,  2638,\n",
            "         2000, 10421,  2015,  4649,  9592, 15596,  2015,  2139,  1049,  1005,\n",
            "         4372, 13149,  4313,  1010, 10364,  4895,  8774,  7505, 21442, 15068,\n",
            "        15333, 26358,  2483, 14451,  1037,  2000, 16446,  4649,  2038, 18117,\n",
            "         4012, 23041,  2015,  1025, 10364, 11265, 15544,  2368, 18704,  4078,\n",
            "        15547, 23345, 10861,  1046,  1005, 10927,  2483,  2139,  1049,  1005,\n",
            "         5463,  2890,  1037,  4078, 18558,  5339, 26639,  5073,  4244,  1012,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "target masks: torch.Size([8, 2, 256, 256])\n",
            "source text: The Commandant dismissed the Negro slaves, and the Paraguayans who presented them with liquor in crystal goblets.\n",
            "target text: Le commandant fit retirer les esclaves nègres et les Paraguains qui servaient à boire dans des gobelets de cristal de roche.\n",
            "source ids: tensor([  101,  1996, 15254,  7219,  1996, 12593,  7179,  1010,  1998,  1996,\n",
            "        13884,  6962,  2040,  3591,  2068,  2007, 13207,  1999,  6121,  2175,\n",
            "         3468,  3215,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "source masks: torch.Size([8, 2, 256, 256])\n",
            "target ids: tensor([  101,  3393, 15254,  4906, 11036,  2099,  4649,  9686, 23650,  2015,\n",
            "        11265, 17603,  2015,  3802,  4649, 11498, 19696,  7076, 21864, 14262,\n",
            "         3567, 11638,  1037,  8945,  7442, 18033,  4078,  2175,  8671,  8454,\n",
            "         2139, 13675, 11921,  2140,  2139, 20162,  1012,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "target masks: torch.Size([8, 2, 256, 256])\n",
            "source text: \"I have my pickaxe, and I shall soon make my way through this wall.\n",
            "target text: J'ai mon pic, et je saurai bien me faire jour à travers ce mur.\n",
            "source ids: tensor([ 101, 1000, 1045, 2031, 2026, 4060, 8528, 2063, 1010, 1998, 1045, 4618,\n",
            "        2574, 2191, 2026, 2126, 2083, 2023, 2813, 1012,  102,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n",
            "source masks: torch.Size([8, 2, 256, 256])\n",
            "target ids: tensor([  101,  1046,  1005,  9932, 12256, 27263,  1010,  3802, 15333,  7842,\n",
            "        24804, 29316,  2033,  4189,  2063,  8183,  3126,  1037, 29053,  8292,\n",
            "        14163,  2099,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "target masks: torch.Size([8, 2, 256, 256])\n",
            "source text: The day before he had noted exactly the hour when the sun disappeared beneath the horizon, making allowance for the refraction.\n",
            "target text: La veille, il avait noté exactement l'heure à laquelle le soleil avait disparu sous l'horizon, en tenant compte de la réfraction.\n",
            "source ids: tensor([  101,  1996,  2154,  2077,  2002,  2018,  3264,  3599,  1996,  3178,\n",
            "         2043,  1996,  3103,  5419,  4218,  1996,  9154,  1010,  2437, 21447,\n",
            "         2005,  1996, 25416, 25533,  1012,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "source masks: torch.Size([8, 2, 256, 256])\n",
            "target ids: tensor([  101,  2474, 15562,  2571,  1010,  6335, 10927,  4183,  3602,  6635,\n",
            "        13665,  1048,  1005,  2002,  5397,  1037,  2474, 22197,  2571,  3393,\n",
            "         7082,  4014, 10927,  4183,  4487, 27694,  2226, 27411,  1048,  1005,\n",
            "         9154,  1010,  4372, 16713,  4012, 13876,  2063,  2139,  2474, 25416,\n",
            "        25533,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "target masks: torch.Size([8, 2, 256, 256])\n",
            "source text: Onrecognising Pierre for whom he had the affection of a faithful dog,he shook off his drowsiness, went for two glasses, and brought out the_Groseillette_.\n",
            "target text: En reconnaissant Pierre, qu'il aimait d'un amour de chienfidèle, il secoua sa torpeur, alla chercher deux verres et apporta lagroseillette.\n",
            "source ids: tensor([  101,  2006,  2890,  3597, 29076,  7741,  5578,  2005,  3183,  2002,\n",
            "         2018,  1996, 12242,  1997,  1037, 11633,  3899,  1010,  2002,  3184,\n",
            "         2125,  2010,  2852, 15568,  9961,  1010,  2253,  2005,  2048,  7877,\n",
            "         1010,  1998,  2716,  2041,  1996,  1035, 24665,  9232, 10484,  4674,\n",
            "         1035,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "source masks: torch.Size([8, 2, 256, 256])\n",
            "target ids: tensor([  101,  4372, 28667,  2239, 28020, 22341,  5578,  1010, 24209,  1005,\n",
            "         6335,  6614,  4886,  2102,  1040,  1005,  4895, 21518,  2139,  9610,\n",
            "         2368, 20740,  2571,  1010,  6335, 10819,  7140,  2050,  7842, 17153,\n",
            "         5051,  3126,  1010, 25699, 24188,  7474, 24756,  2310, 14343,  2015,\n",
            "         3802, 10439, 11589,  2050,  2474, 16523,  9232, 10484,  4674,  1012,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "target masks: torch.Size([8, 2, 256, 256])\n",
            "source text: LETTER\n",
            "target text: LETTRE\n",
            "source ids: tensor([ 101, 3661,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n",
            "source masks: torch.Size([8, 2, 256, 256])\n",
            "target ids: tensor([ 101, 2292, 7913,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n",
            "target masks: torch.Size([8, 2, 256, 256])\n",
            "source text: \"Poor fellow!\" murmured the engineer.\n",
            "target text: «Pauvre abandonné!» murmura l'ingénieur.\n",
            "source ids: tensor([ 101, 1000, 3532, 3507,  999, 1000, 7152, 1996, 3992, 1012,  102,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n",
            "source masks: torch.Size([1, 2, 256, 256])\n",
            "target ids: tensor([  101,  1077, 29025, 12229, 10824,  2638,   999,  1090, 20227,  2050,\n",
            "         1048,  1005, 13749, 18595, 11236,  1012,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "target masks: torch.Size([1, 2, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class InputEmbedding(nn.Module):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.d_model = d_model\n",
        "    # nn.Embedding is a dictionary kind of a layer that just maps number to the vector every time and this vector is learned by the model\n",
        "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # According to \"Attention is all you need\", in the embedding layers, we need to multiply those weights by sqrt(emb_dim)\n",
        "    return self.embedding(x) * (self.d_model ** 0.5)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(nn.Module):\n",
        "  def __init__(self, d_model, seq_len):\n",
        "    super().__init__()\n",
        "\n",
        "    # pe = torch.zeros(seq_len, d_model)\n",
        "    pe = torch.zeros(seq_len, d_model)\n",
        "\n",
        "    pos = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
        "    div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000) / d_model))\n",
        "\n",
        "    pe[:,0::2] = torch.sin(pos*div)\n",
        "    pe[:,1::2] = torch.cos(pos*div)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x = x + self.pe.requires_grad_(False)\n",
        "    x = x + self.pe[:, :x.shape[1],:].requires_grad_(False)\n",
        "    # return x.unsqueeze(0)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "fiycekyidGLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_embedding = InputEmbedding(tokenizer.vocab_size, config['d_model'])\n",
        "positional_encoding = PositionalEmbedding(config['d_model'], config['seq_len'])\n",
        "\n",
        "train_ds = BilingualDataset(train, src_tokenizer, tgt_tokenizer, config)\n",
        "print(train_ds.__getitem__(1)['source_txt'])\n",
        "print(train_ds.__getitem__(1)['target_txt'])\n",
        "print(train_ds.__getitem__(1)['source_ids'].size())\n",
        "\n",
        "src_enc = input_embedding(train_ds.__getitem__(1)['source_ids'])\n",
        "print(f\"\\nSource after embedded size: {src_enc.size()}\")\n",
        "src_pe = positional_encoding(src_enc)\n",
        "print(f\"Source after positional embedded size: {src_pe.size()}\\n\")\n",
        "\n",
        "\n",
        "tgt_enc = input_embedding(train_ds.__getitem__(1)['source_ids'])\n",
        "print(f\"Target after embedded size: {tgt_enc.size()}\")\n",
        "tgt_pe = positional_encoding(tgt_enc)\n",
        "print(f\"Target after positional embedded size: {tgt_pe.size()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scfpzaCxde3N",
        "outputId": "dc0516ab-4f0b-41d6-e4fa-9e795fca6e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Is he living with you?\"\n",
            "-- Est-ce qu'il demeure avec vous?\n",
            "torch.Size([256])\n",
            "\n",
            "Source after embedded size: torch.Size([256, 256])\n",
            "Source after positional embedded size: torch.Size([1, 256, 256])\n",
            "\n",
            "Target after embedded size: torch.Size([256, 256])\n",
            "Target after positional embedded size: torch.Size([1, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.d_model = config['d_model']\n",
        "    self.d_ff = self.d_model * 4\n",
        "\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Linear(self.d_model, self.d_ff),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(self.d_ff, self.d_model),\n",
        "        nn.Dropout(config['dropout'])\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.ffn(x)\n"
      ],
      "metadata": {
        "id": "UbwgPCgWdrc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "    self.d_model = config['d_model']\n",
        "    self.h = config['h']\n",
        "\n",
        "    assert self.d_model % self.h == 0, \"d_model must be divisible by h\"\n",
        "\n",
        "\n",
        "    self.d_k = self.d_model // self.h\n",
        "    # Query, key, value\n",
        "    self.W_q = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "    self.W_k = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "    self.W_v = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "\n",
        "    # Last Layer\n",
        "    self.W_o = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "\n",
        "    # dropout\n",
        "    self.dropout = nn.Dropout(config['dropout'])\n",
        "\n",
        "  def forward(self, q, k, v, mask):\n",
        "\n",
        "    h = self.h\n",
        "    d_k = self.d_k\n",
        "    d_model = self.d_model\n",
        "\n",
        "    query = self.W_q(q)\n",
        "    key = self.W_k(k)\n",
        "    value = self.W_v(v)\n",
        "\n",
        "    # It's necessary since decode process will be (target, src_output, src_output, mask)\n",
        "    # which means, q_seq_len and k_seq_len will be different.\n",
        "    q_B, q_seq_len, _ = query.size()\n",
        "    k_B, k_seq_len, _ = key.size()\n",
        "    v_B, v_seq_len, _ = value.size()\n",
        "    # size: (Batch, Seq_len, d_model) -> (Batch, Seq_len, h, d_model // h)\n",
        "    query = query.view(q_B, q_seq_len, h, d_k)\n",
        "    key = key.view(k_B, k_seq_len, h, d_k)\n",
        "    value = value.view(v_B, v_seq_len, h, d_k)\n",
        "\n",
        "    # (Batch, Seq_len, h, d_k) -> (Batch, h, Seq_len, d_k)\n",
        "    # (Batch, h, Seq_len, d_k) -> (Batch * h, Seq_len, d_k)\n",
        "    query = query.transpose(1,2).contiguous().view(q_B * h, q_seq_len, d_k)\n",
        "    key = key.transpose(1,2).contiguous().view(k_B * h, k_seq_len, d_k)\n",
        "    value = value.transpose(1,2).contiguous().view(v_B * h, v_seq_len, d_k)\n",
        "\n",
        "    # Attention: W\n",
        "    # paying attention to each sequences, therefore size should be (Batch *h, Seq_len, Seq_len)\n",
        "    W = query @ key.transpose(1,2)\n",
        "    W = W / (d_model ** 0.5)\n",
        "\n",
        "    # If there is a mask, make masked spots -INF\n",
        "    # seq_len must be equal to query's sequence length.\n",
        "    if mask is not None:\n",
        "      mask = mask.view(k_B * h, k_seq_len, k_seq_len) # (B, h, Seq_len, Seq_len) => (B * h, Seq_len, Seq_len)\n",
        "      if q_seq_len != k_seq_len:\n",
        "        mask = mask[:,:q_seq_len,:]\n",
        "      W = W.masked_fill_(mask == 0, float('-inf'))\n",
        "\n",
        "    W = W.softmax(dim = -1)\n",
        "    # drop out\n",
        "    W = self.dropout(W)\n",
        "\n",
        "    out = W @ value # (B * h, seq_len, d_k)\n",
        "    B, Seq_len, d_k = out.size()\n",
        "    B = B // h\n",
        "    out = out.view(B, h, Seq_len, d_k)\n",
        "    out = out.transpose(1,2).contiguous().view(B, Seq_len, h * d_k)\n",
        "    return self.W_o(out)\n"
      ],
      "metadata": {
        "id": "2oh0eRU0hJuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(EncoderBlock, self).__init__()\n",
        "\n",
        "    self.d_model = config['d_model']\n",
        "\n",
        "    self.MultiHeadAttention = MultiHeadAttention(config)\n",
        "\n",
        "    self.ln_1 = nn.LayerNorm(self.d_model)\n",
        "    self.ln_2 = nn.LayerNorm(self.d_model)\n",
        "    self.FeedForward = FeedForward(config)\n",
        "\n",
        "  def forward(self, x, src_mask):\n",
        "    x = x + self.MultiHeadAttention(x, x, x, src_mask)\n",
        "    x = self.ln_1(x)\n",
        "    x = x + self.FeedForward(x)\n",
        "    x = self.ln_2(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "bQ2sAg-xhKJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.depth = config['depth']\n",
        "    # Encoder: blocks of encoder blocks\n",
        "    self.blocks = nn.ModuleList([\n",
        "        EncoderBlock(config) for _ in range(self.depth)\n",
        "    ])\n",
        "    self.blocks = nn.Sequential(*self.blocks)\n",
        "\n",
        "  def forward(self, x, src_mask):\n",
        "    for block in self.blocks:\n",
        "      x = block(x, src_mask)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZxrUnTP8hLJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(DecoderBlock, self).__init__()\n",
        "\n",
        "    self.d_model = config['d_model']\n",
        "\n",
        "    self.SelfHeadAttention = MultiHeadAttention(config)\n",
        "    self.CrossHeadAttention = MultiHeadAttention(config)\n",
        "\n",
        "    self.ln_1 = nn.LayerNorm(self.d_model)\n",
        "    self.ln_2 = nn.LayerNorm(self.d_model)\n",
        "    self.ln_3 = nn.LayerNorm(self.d_model)\n",
        "\n",
        "    self.FeedForward = FeedForward(config)\n",
        "\n",
        "  def forward(self, x, encoder_out, src_mask, tgt_mask):\n",
        "    # x: target, in our case positively-toned comment\n",
        "    x = x + self.SelfHeadAttention(x, x, x, tgt_mask)\n",
        "    x = self.ln_1(x)\n",
        "    x = x + self.CrossHeadAttention(x, encoder_out, encoder_out, src_mask)\n",
        "    x = self.ln_2(x)\n",
        "    x = x + self.FeedForward(x)\n",
        "    x = self.ln_3(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "UDmsXTtahL5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.depth = config['depth']\n",
        "\n",
        "    self.blocks = nn.ModuleList([\n",
        "        DecoderBlock(config) for _ in range(self.depth)\n",
        "    ])\n",
        "    self.blocks = nn.Sequential(*self.blocks)\n",
        "\n",
        "  def forward(self, x, encoder_out, src_mask, tgt_mask):\n",
        "    for block in self.blocks:\n",
        "      x = block(x, encoder_out, src_mask, tgt_mask)\n",
        "    return x"
      ],
      "metadata": {
        "id": "8P85TDYGhMxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, config, vocab_size):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(config)\n",
        "    self.decoder = Decoder(config)\n",
        "\n",
        "    self.d_model = config['d_model']\n",
        "    self.seq_len = config['seq_len']\n",
        "\n",
        "    # Input Embedding for source and target\n",
        "    self.src_embedding = InputEmbedding(vocab_size, self.d_model)\n",
        "    self.tgt_embedding = InputEmbedding(vocab_size, self.d_model)\n",
        "\n",
        "    # Positional Embedding for source and target\n",
        "    self.src_pos_embedding = PositionalEmbedding(self.d_model, self.seq_len)\n",
        "    self.tgt_pos_embedding = PositionalEmbedding(self.d_model, self.seq_len)\n",
        "\n",
        "    self.norm = nn.LayerNorm(self.d_model)\n",
        "    self.projection = nn.Linear(self.d_model, vocab_size)\n",
        "\n",
        "  def encode(self, source, src_mask):\n",
        "    source = self.src_embedding(source)\n",
        "    source = self.src_pos_embedding(source)\n",
        "    return self.encoder(source, src_mask)\n",
        "\n",
        "  def decode(self, target, encoder_out, src_mask, tgt_mask):\n",
        "    target = self.tgt_embedding(target)\n",
        "    target = self.tgt_pos_embedding(target)\n",
        "    return self.decoder(target, encoder_out, src_mask, tgt_mask)\n",
        "\n",
        "  def forward(self, decoder_out):\n",
        "    out = self.norm(decoder_out)\n",
        "    out = self.projection(out)\n",
        "    return torch.log_softmax(out, dim=-1)\n"
      ],
      "metadata": {
        "id": "u08ot91LhNhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# path for saving model\n",
        "path = \"./Translator\"\n",
        "pathlib.Path(f\"./{path}/\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# hyperparameters\n",
        "lr = config['lr']\n",
        "num_epochs = 1\n",
        "\n",
        "# configuration\n",
        "vocab_size = tokenizer.vocab_size\n",
        "config = get_config(1, vocab_size)\n",
        "\n",
        "# model, optim, loss (cross entropy loss)\n",
        "model = Transformer(config, vocab_size).to(device)\n",
        "print(model)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
        "ce_loss = nn.CrossEntropyLoss(ignore_index = 0, label_smoothing=0.1).to(device)\n",
        "\n",
        "# training\n",
        "for epoch in range(num_epochs):\n",
        "  torch.cuda.empty_cache()\n",
        "  model.train()\n",
        "  batch_iterator = tqdm(train_loader, desc = f'Processing epoch {epoch:02d}')\n",
        "  for batch in batch_iterator:\n",
        "    source = batch['source_ids'].to(device)\n",
        "    target = batch['target_ids'].to(device)\n",
        "    src_mask = batch['source_masks'].to(device)\n",
        "    tgt_mask = batch['target_masks'].to(device)\n",
        "    B, seq_len = source.size()\n",
        "\n",
        "    # forward pass\n",
        "    # def encode(self, source, src_mask):\n",
        "    encoder_out = model.encode(source, None)\n",
        "    # def decode(self, target, encoder_out, src_mask, tgt_mask):\n",
        "    decoder_out = model.decode(target, encoder_out, None, None)\n",
        "    out = model.forward(decoder_out) # size:(Batch, Seq_len, tgt_vocab_size)\n",
        "\n",
        "    out = out.view(B*seq_len, vocab_size)\n",
        "    target = target.view(B*seq_len)\n",
        "\n",
        "    loss = ce_loss(out, target)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    batch_iterator.set_postfix(loss=f\"{loss.item():6.3f}\")\n",
        "  torch.save(model.state_dict(), f'{path}/{epoch}.pth')\n",
        "\n",
        "torch.save(model.state_dict(), f'{path}/final_model.pth')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBOxFfrjhOlh",
        "outputId": "2a13b742-3f24-43c0-8f37-61893f00c43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer(\n",
            "  (encoder): Encoder(\n",
            "    (blocks): Sequential(\n",
            "      (0): EncoderBlock(\n",
            "        (MultiHeadAttention): MultiHeadAttention(\n",
            "          (W_q): Linear(in_features=256, out_features=256, bias=False)\n",
            "          (W_k): Linear(in_features=256, out_features=256, bias=False)\n",
            "          (W_v): Linear(in_features=256, out_features=256, bias=False)\n",
            "          (W_o): Linear(in_features=256, out_features=256, bias=False)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (FeedForward): FeedForward(\n",
            "          (ffn): Sequential(\n",
            "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "            (1): ReLU()\n",
            "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "            (3): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (blocks): Sequential(\n",
            "      (0): DecoderBlock(\n",
            "        (SelfHeadAttention): MultiHeadAttention(\n",
            "          (W_q): Linear(in_features=256, out_features=256, bias=False)\n",
            "          (W_k): Linear(in_features=256, out_features=256, bias=False)\n",
            "          (W_v): Linear(in_features=256, out_features=256, bias=False)\n",
            "          (W_o): Linear(in_features=256, out_features=256, bias=False)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (CrossHeadAttention): MultiHeadAttention(\n",
            "          (W_q): Linear(in_features=256, out_features=256, bias=False)\n",
            "          (W_k): Linear(in_features=256, out_features=256, bias=False)\n",
            "          (W_v): Linear(in_features=256, out_features=256, bias=False)\n",
            "          (W_o): Linear(in_features=256, out_features=256, bias=False)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (ln_3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (FeedForward): FeedForward(\n",
            "          (ffn): Sequential(\n",
            "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "            (1): ReLU()\n",
            "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "            (3): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (src_embedding): InputEmbedding(\n",
            "    (embedding): Embedding(30522, 256)\n",
            "  )\n",
            "  (tgt_embedding): InputEmbedding(\n",
            "    (embedding): Embedding(30522, 256)\n",
            "  )\n",
            "  (src_pos_embedding): PositionalEmbedding()\n",
            "  (tgt_pos_embedding): PositionalEmbedding()\n",
            "  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (projection): Linear(in_features=256, out_features=30522, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 00: 100%|██████████| 3178/3178 [04:52<00:00, 10.85it/s, loss=1.374]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#validation\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  batch_iterator = tqdm(val_loader)\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for idx, batch in enumerate(batch_iterator, 0):\n",
        "    source = batch['source_ids'].to(device)\n",
        "    target = batch['target_ids'].to(device)\n",
        "    src_mask = batch['source_masks'].to(device)\n",
        "    tgt_mask = batch['target_masks'].to(device)\n",
        "\n",
        "    B, seq_len = source.size()\n",
        "\n",
        "    # forward pass\n",
        "    # def encode(self, source, src_mask):\n",
        "    encoder_out = model.encode(source, src_mask)\n",
        "    # def decode(self, target, encoder_out, src_mask, tgt_mask):\n",
        "    decoder_out = model.decode(target, encoder_out, src_mask, tgt_mask)\n",
        "    out = model.forward(decoder_out)\n",
        "    out = out.view(B*seq_len, vocab_size)\n",
        "\n",
        "    target = target.view(B*seq_len)\n",
        "\n",
        "    loss = ce_loss(out, target)\n",
        "\n",
        "    pred = torch.max(out, dim=-1).indices\n",
        "\n",
        "    total += target.shape[0]\n",
        "    correct += sum(pred == target)\n",
        "    batch_iterator.set_postfix(loss=f\"{loss.item():6.3f}\")\n",
        "\n",
        "    if idx % 1000 ==0:\n",
        "      txt_pred = tokenizer.decode(pred).replace(\"[PAD]\", \"\")\n",
        "      print(f\"\\nOriginal comments: {batch['source_txt']}\\n\")\n",
        "      print(f\"Generated comments: {txt_pred}\\n\")\n",
        "      print(f\"Target comments: {batch['target_txt']}\\n\")\n",
        "\n",
        "print(f'\\nAccuracy: {100 * (correct / total)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s97W_19kxPb",
        "outputId": "a1019b39-02f8-4e17-ac33-d34dce17ba7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 17/25417 [00:00<05:09, 82.07it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['\"By no means.']\n",
            "\n",
            "Generated comments: [CLS] – surtout pas! [SEP]                                                                                                                                                                                                                                                        \n",
            "\n",
            "Target comments: ['– Surtout pas !']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 1013/25417 [00:12<04:50, 84.10it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['A pretty woman, on my word! and who must needs love me madly to have taken me in that fashion. By the way,\" said he, rising suddenly, with that sentiment of the true which formed the foundation of his character and his philosophy, \"I don\\'t know very well how it happens, but I am her husband!\"']\n",
            "\n",
            "Generated comments: [CLS] mon mauvais genie! mon bon ange! – une jolie femme, sur ma parole! – et qui doit m ’ aimer a la folie pour m ’ avoir pris de la sorte. – a propos, dit - il en se levant tout a coup avec ce sentiment du vrai qui faisait le fond de son caractere et de sa philosophie, je ne sais trop comment cela se fait, mais je suis son mari! » [SEP]                                                                                                                                              \n",
            "\n",
            "Target comments: ['Mon mauvais génie ! mon bon ange ! – Une jolie femme, sur ma parole ! – et qui doit m’aimer à la folie pour m’avoir pris de la sorte. – À propos, dit-il en se levant tout à coup avec ce sentiment du vrai qui faisait le fond de son caractère et de sa philosophie, je ne sais trop comment cela se fait, mais je suis son mari ! »']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 2011/25417 [00:25<04:38, 84.06it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['Some Brahmins, clad in all the sumptuousness of Oriental apparel, and leading a woman who faltered at every step, followed.']\n",
            "\n",
            "Generated comments: [CLS] derriere eux, quelques brahmanes, dans toute la somptuosite de leur costume oriental, trainaient une femme qui se soutenait a peine. [SEP]                                                                                                                                                                                                                   \n",
            "\n",
            "Target comments: ['Derrière eux, quelques brahmanes, dans toute la somptuosité de leur costume oriental, traînaient une femme qui se soutenait à peine.']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 3014/25417 [00:37<04:21, 85.57it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['We may take it, therefore, that the letter was composed by an educated man who wished to pose as an uneducated one, and his effort to conceal his own writing suggests that that writing might be known, or come to be known, by you.']\n",
            "\n",
            "Generated comments: [CLS] nous pouvons donc deduire que ce message a ete compose par un individu instruit qui voulait passer pour un homme du peuple : et le fait qu ’ il a voulu deguiser sa propre ecriture suggere que cette ecriture pouvait vous etre connue, ou vous devenir connue. [SEP]                                                                                                                                                                   \n",
            "\n",
            "Target comments: ['Nous pouvons donc déduire que ce message a été composé par un individu instruit qui voulait passer pour un homme du peuple : et le fait qu’il a voulu déguiser sa propre écriture suggère que cette écriture pouvait vous être connue, ou vous devenir connue.']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 4012/25417 [00:50<04:13, 84.44it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['He was not better dressed than of old, for I well knew the old brown suit that he wore.']\n",
            "\n",
            "Generated comments: [CLS] ce netait pas qu'il fut mieux habille que jadis, car je reconnus le vieux costume brun qu'il portait. [SEP]                                                                                                                                                                                                                         \n",
            "\n",
            "Target comments: [\"Ce n\\x92était pas qu'il fût mieux habillé que jadis, car je reconnus le vieux costume brun qu'il portait.\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 5008/25417 [01:02<04:12, 80.85it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: [\"'This is a bold and healthy mind,' he said to himself, 'but _corpus debile_ (a frail body).\"]\n",
            "\n",
            "Generated comments: [CLS] voila un esprit hardi et sain, se disait - il, mais corpus debile ( le corps est faible ). [SEP]                                                                                                                                                                                                                             \n",
            "\n",
            "Target comments: ['Voilà un esprit hardi et sain, se disait-il, mais corpus debile (le corps est faible).']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 6016/25417 [01:15<03:52, 83.30it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: [\"'Brother,' says she, 'you may come if you please.'\"]\n",
            "\n",
            "Generated comments: [CLS] - - mon frere, dit - elle, tu peux rentrer s'il te plait. [SEP]                                                                                                                                                                                                                                      \n",
            "\n",
            "Target comments: [\"--Mon frère, dit-elle, tu peux rentrer s'il te plaît.\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 7010/25417 [01:28<03:52, 79.09it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['She stooped to open the small iron gate, and she made haste to inspect anxiously the lonely spot.']\n",
            "\n",
            "Generated comments: [CLS] elle ouvrit, en se penchant, une petite grille, et se hata d ’ inspecter avec inquietude le lieu solitaire. [SEP]                                                                                                                                                                                                                            \n",
            "\n",
            "Target comments: ['Elle ouvrit, en se penchant, une petite grille, et se hâta d’inspecter avec inquiétude le lieu solitaire.']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 8010/25417 [01:40<03:23, 85.69it/s, loss=0.007]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['I roused, and interested you, because I was so unlike _them_. Had you not been really amiable, you would have hated me for it; but in spite of the pains you took to disguise yourself, your feelings were always noble and just; and in your heart, you thoroughly despised the persons who so assiduously courted you.']\n",
            "\n",
            "Generated comments: [CLS] vous etiez fatigue de ces femmes qui ne faisaient rien que pour obtenir votre approbation. c ’ est parce que je leur ressemblais si peu que j ’ ai eveille votre interet. [SEP]                                                                                                                                                                                                      \n",
            "\n",
            "Target comments: ['Vous étiez fatigué de ces femmes qui ne faisaient rien que pour obtenir votre approbation. C’est parce que je leur ressemblais si peu que j’ai éveillé votre intéret.']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 9013/25417 [01:52<03:19, 82.31it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['The link of the chain, forced open by him in circumstances, alas, so different, had not been mended.']\n",
            "\n",
            "Generated comments: [CLS] le chainon, jadis force par lui en des circonstances, helas! si differentes, n ’ avait point ete raccommode. [SEP]                                                                                                                                                                                                                          \n",
            "\n",
            "Target comments: ['Le chaînon, jadis forcé par lui en des circonstances, hélas ! si différentes, n’avait point été raccommodé.']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 10012/25417 [02:05<03:03, 84.17it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['Doubtless he was accustomed to such reproaches, for he listened to me calm and smiling, with his arms crossed over his breast. Then, when he thought I had said all, he advanced toward me; I sprang toward the table, I seized a knife, I placed it to my breast.']\n",
            "\n",
            "Generated comments: [CLS] « tout ce que le coeur d'une femme peut contenir de superbe mepris et de paroles dedaigneuses, je le versai sur cet homme ; sans doute, il etait habitue a de pareils reproches ; car il m'ecouta calme, souriant, et les bras croises sur la poitrine ; puis, lorsqu'il crut que j'avais tout dit, il s'avanca vers moi ; je bondis vers la table, je saisis un couteau, je l'appuyai sur ma poitrine. [SEP]                                                                                                                \n",
            "\n",
            "Target comments: [\"«Tout ce que le coeur d'une femme peut contenir de superbe mépris et de paroles dédaigneuses, je le versai sur cet homme; sans doute, il était habitué à de pareils reproches; car il m'écouta calme, souriant, et les bras croisés sur la poitrine; puis, lorsqu'il crut que j'avais tout dit, il s'avança vers moi; je bondis vers la table, je saisis un couteau, je l'appuyai sur ma poitrine.\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 11010/25417 [02:18<02:54, 82.55it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['It was remarkable, too, I had but three subjects, and they were of three different religions—my man Friday was a Protestant, his father was a Pagan and a cannibal, and the Spaniard was a Papist.']\n",
            "\n",
            "Generated comments: [CLS] chose surtout remarquable! je n'avais que trois sujets et ils etaient de trois religions differentes : mon homme vendredi etait protestant, son pere etait idolatre et cannibale, et l'espagnol etait papiste. [SEP]                                                                                                                                                                                            \n",
            "\n",
            "Target comments: [\"Chose surtout remarquable! je n'avais que trois sujets et ils étaient de trois religions différentes: Mon homme Vendredi était protestant, son père était idolâtre et cannibale, et l'Espagnol était papiste.\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 12012/25417 [02:31<02:46, 80.69it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['She replied in her cheerful way, without blushing:']\n",
            "\n",
            "Generated comments: [CLS] elle repondit de son air gai, sans rougeur : [SEP]                                                                                                                                                                                                                                                \n",
            "\n",
            "Target comments: ['Elle répondit de son air gai, sans rougeur:']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 13014/25417 [02:43<02:29, 83.02it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: [\"Like certain flocks of birds, whose speed they equal, these tuna swim in triangle formation, which prompted the ancients to say they'd boned up on geometry and military strategy.\"]\n",
            "\n",
            "Generated comments: [CLS] ils nageaient en triangle, comme certaines troupes d'oiseaux dont ils egalaient la rapidite, ce qui faisait dire aux anciens que la geometrie et la strategie leur etaient familieres. [SEP]                                                                                                                                                                                                 \n",
            "\n",
            "Target comments: [\"Ils nageaient en triangle, comme certaines troupes d'oiseaux dont ils égalaient la rapidité, ce qui faisait dire aux anciens que la géométrie et la stratégie leur étaient familières.\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 14012/25417 [02:56<02:25, 78.35it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['Why?']\n",
            "\n",
            "Generated comments: [CLS] dans quel but? [SEP]                                                                                                                                                                                                                                                         \n",
            "\n",
            "Target comments: ['Dans quel but?']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 15011/25417 [03:08<02:01, 85.55it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['Mais ils étaient toujours sous la juridiction des Saints et ils ne tarderent pas a en avoir la preuve.']\n",
            "\n",
            "Generated comments: [CLS] they soon had a proof, however, that they were still within the rifle of the saints. [SEP]                                                                                                                                                                                                                                           \n",
            "\n",
            "Target comments: ['They soon had a proof, however, that they were still within the jurisdiction of the Saints.']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 16015/25417 [03:21<01:53, 82.62it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: [\"A contract which binds me without putting you under any obligation is unfair, I must decline.'\"]\n",
            "\n",
            "Generated comments: [CLS] un engagement qui me lie sans vous obliger a rien n ’ est point egal, je le refuse. [SEP]                                                                                                                                                                                                                                     \n",
            "\n",
            "Target comments: ['Un engagement qui me lie sans vous obliger à rien n’est point égal, je le refuse.']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 17009/25417 [03:34<01:41, 82.62it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['\"It is the custom in war,\" said d’Artagnan, \"why should it not be the custom in a duel?\"']\n",
            "\n",
            "Generated comments: [CLS] - - c'est l'habitude a la guerre, dit d'artagnan ; pourquoi ne serait - ce pas l'habitude dans un duel? [SEP]                                                                                                                                                                                                                        \n",
            "\n",
            "Target comments: [\"-- C'est l'habitude à la guerre, dit d'Artagnan; pourquoi ne serait-ce pas l'habitude dans un duel?\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 18010/25417 [03:46<01:33, 78.84it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['It was impossible, therefore, to return every day to the Chimneys, and it was agreed that the little colony should camp under a hut of branches, so that the important operation could be followed night and day.']\n",
            "\n",
            "Generated comments: [CLS] il ne fallait donc pas songer a revenir chaque jour aux cheminees, et il fut convenu que la petite colonie camperait sous une hutte de branchages, de maniere que l'importante operation fut suivie nuit et jour. [SEP]                                                                                                                                                                                             \n",
            "\n",
            "Target comments: [\"Il ne fallait donc pas songer à revenir chaque jour aux Cheminées, et il fut convenu que la petite colonie camperait sous une hutte de branchages, de manière que l'importante opération fût suivie nuit et jour.\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 19014/25417 [03:59<01:21, 78.12it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['Never had he been so madly in love.']\n",
            "\n",
            "Generated comments: [CLS] jamais il n ’ avait ete aussi fou d ’ amour. [SEP]                                                                                                                                                                                                                                             \n",
            "\n",
            "Target comments: ['Jamais il n’avait été aussi fou d’amour.']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▊  | 20011/25417 [04:12<01:05, 82.98it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['\"Then I was jealous of Jean,\" thought he.']\n",
            "\n",
            "Generated comments: [CLS] - - donc j'ai ete jaloux de jean, pensait - il. [SEP]                                                                                                                                                                                                                                         \n",
            "\n",
            "Target comments: [\"--Donc j'ai été jaloux de Jean, pensait-il.\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 21015/25417 [04:24<00:54, 81.15it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['\"Oh, when I said I was alone,\" said Milady, hoping to make the novice talk by talking of herself, \"it is not for want of friends in high places; but these friends themselves tremble before the cardinal. The queen herself does not dare to oppose the terrible minister.']\n",
            "\n",
            "Generated comments: [CLS] - - oh! quand j'ai dit que j'etais seule, dit milady, esperant faire parler la novice en parlant d'elle - meme, ce n'est pas faute d'avoir aussi quelques connaissances haut placees ; mais ces connaissances tremblent elles - memes devant le cardinal : la reine elle - meme n'ose pas soutenir contre le terrible ministre ; j'ai la preuve que sa majeste, malgre son excellent coeur, a plus d'une fois ete obligee d'abandonner a la colere de son eminence les personnes qui l'avaient servie. [SEP]                                                                                       \n",
            "\n",
            "Target comments: [\"-- Oh! quand j'ai dit que j'étais seule, dit Milady, espérant faire parler la novice en parlant d'elle-même, ce n'est pas faute d'avoir aussi quelques connaissances haut placées; mais ces connaissances tremblent elles-mêmes devant le cardinal: la reine elle-même n'ose pas soutenir contre le terrible ministre; j'ai la preuve que Sa Majesté, malgré son excellent coeur, a plus d'une fois été obligée d'abandonner à la colère de Son Éminence les personnes qui l'avaient servie.\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 22014/25417 [04:37<00:39, 85.31it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['\"I am as innocent as you are; and I can prove it.\"']\n",
            "\n",
            "Generated comments: [CLS] je suis aussi innocent que vous et je puis le prouver. [SEP]                                                                                                                                                                                                                                            \n",
            "\n",
            "Target comments: ['Je suis aussi innocent que vous et je puis le prouver.']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 23017/25417 [04:49<00:29, 82.48it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['\"Need I go further where every word is an agony?\"']\n",
            "\n",
            "Generated comments: [CLS] ai - je besoin d'en dire davantage, quand chaque mot est un supplice pour moi? [SEP]                                                                                                                                                                                                                                  \n",
            "\n",
            "Target comments: [\"Ai-je besoin d'en dire davantage, quand chaque mot est un supplice pour moi?\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 24015/25417 [05:02<00:17, 82.02it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: [\"The following morning at nine o'clock, when Julien came down from his prison to enter the great hall of the Law Courts, it was with the utmost difficulty that the gendarmes succeeded in clearing a passage through the immense crowd that packed the courtyard.\"]\n",
            "\n",
            "Generated comments: [CLS] le lendemain a neuf heures, quand julien descendit de sa prison pour aller dans la grande salle du palais de justice, ce fut avec beaucoup de peine que les gendarmes parvinrent a ecarter la foule immense entassee dans la cour. [SEP]                                                                                                                                                                                             \n",
            "\n",
            "Target comments: ['Le lendemain à neuf heures, quand Julien descendit de sa prison pour aller dans la grande salle du Palais de Justice, ce fut avec beaucoup de peine que les gendarmes parvinrent à écarter la foule immense entassée dans la cour.']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 25014/25417 [05:14<00:04, 84.70it/s, loss=0.000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original comments: ['Thus, we never see the true state of our condition till it is illustrated to us by its contraries, nor know how to value what we enjoy, but by the want of it.']\n",
            "\n",
            "Generated comments: [CLS] ainsi nous ne voyons jamais le veritable etat de notre position avant qu'il n'ait ete rendu evident par des fortunes contraires, et nous n'apprecions nos jouissances qu'apres que nous les avons perdues. [SEP]                                                                                                                                                                                            \n",
            "\n",
            "Target comments: [\"Ainsi nous ne voyons jamais le véritable état de notre position avant qu'il n'ait été rendu évident par des fortunes contraires, et nous n'apprécions nos jouissances qu'après que nous les avons perdues.\"]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25417/25417 [05:20<00:00, 79.39it/s, loss=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 99.97456359863281%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(val_loader)\n",
        "batch = next(dataiter)\n",
        "source = batch['source_ids'].to(device)\n",
        "src_mask = batch['source_masks'].to(device)\n",
        "encoder_out = model.encode(source, None)\n",
        "src_txt = batch['source_txt']\n",
        "print(batch['source_txt'])\n",
        "print(batch['target_txt'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-XxeVQcJXlK",
        "outputId": "3dce4d35-ec11-4043-834a-9816b45a998a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\"What?\"']\n",
            "['-- Laquelle?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(dataiter)\n",
        "\n",
        "target = batch['target_ids'].to(device)\n",
        "tgt_mask = batch['target_masks'].to(device)\n",
        "print(batch['source_txt'])\n",
        "print(batch['target_txt'])\n",
        "\n",
        "B, seq_len = source.size()\n",
        "\n",
        "# forward pass\n",
        "# def encode(self, source, src_mask):\n",
        "\n",
        "# def decode(self, target, encoder_out, src_mask, tgt_mask):\n",
        "decoder_out = model.decode(target, encoder_out, None, None)\n",
        "out = model.forward(decoder_out)\n",
        "out = out.view(B*seq_len, vocab_size)\n",
        "\n",
        "target = target.view(B*seq_len)\n",
        "\n",
        "loss = ce_loss(out, target)\n",
        "\n",
        "pred = torch.max(out, dim=-1).indices\n",
        "\n",
        "total += target.shape[0]\n",
        "correct += sum(pred == target)\n",
        "batch_iterator.set_postfix(loss=f\"{loss.item():6.3f}\")\n",
        "\n",
        "txt_pred = tokenizer.decode(pred).replace(\"[PAD]\", \"\")\n",
        "print(f\"\\nOriginal comments: {src_txt}\\n\")\n",
        "print(f\"Generated comments: {txt_pred}\\n\")\n",
        "print(f\"Target comments: {batch['target_txt']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zdQkWV2JRCJ",
        "outputId": "60c05be1-29f7-4ee7-83f6-5c30b3a64a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['For a moment he stood panting, wiping his forehead, calming the bounds of his heart.']\n",
            "[\"Il resta un instant encore, haletant, a s'essuyer le front, a calmer les bonds de son coeur.\"]\n",
            "\n",
            "Original comments: ['\"What?\"']\n",
            "\n",
            "Generated comments: [CLS] il resta un instant encore, haletant, a s'essuyer le front, a calmer les bonds de son coeur. [SEP] herb occupationpie herb herb herb herb occupationpie herb herb occupation occupation herb occupation herb herb herb herbpie herb occupation occupationpie occupation occupation herb herb herb occupation herb herb occupation herb herb herb herb herbpie herb herb herb herb herb occupation herb herb herbpie herb herb occupation herbast herb herb occupation herb herb herb herb herb herb herbpiepie herb occupation herbpieast herb herbpie herb herb herb occupationpie herb herb herb herb herb occupation herb herb herb occupation herb occupation herb herb herb herb herb occupation herb herbpie herb herb occupation herb herb occupation occupation occupation herb herbpie herb herb occupation herbpiepie herb herb herbpie herb herbast herb herb occupation herbpie herb herb herb herb herb occupation herb herbpiepie herbpie herb herb herb herbpie occupationpie herbpiepie occupation herb herb occupation occupation herb herbpie herb occupation herb herbpie herbpie herb herb herb herbpie occupationpie occupation herbpie occupation herb herbpie herb occupation herb herb herb occupation herbpie herb occupation herb occupation herb occupation occupation herb herbpie herb occupation occupation herb herb occupation herb occupation herb occupation herb occupation herbpie herbpie herb occupation herbpie herbpiepie occupation herb herb\n",
            "\n",
            "Target comments: [\"Il resta un instant encore, haletant, a s'essuyer le front, a calmer les bonds de son coeur.\"]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INPUT EMBEDDING + POS EMBEDDING DIMENSION CHECK"
      ],
      "metadata": {
        "id": "z4VGr6-D3y2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "d_model = 256\n",
        "seq_len = 256\n",
        "d_k = d_model // h\n",
        "\n",
        "# When generating target...\n",
        "x = torch.empty(1,1).fill_(101).type_as(source).to(device)\n",
        "print(f\"source size: {x.size()}\\n\")\n",
        "\n",
        "embedding = nn.Embedding(vocab_size, d_model).to(device)\n",
        "x = embedding(x) * (d_model ** 0.5)\n",
        "print(f\"after embedding: {x.size()}\\n\")\n",
        "\n",
        "pe = torch.zeros(seq_len, d_model).to(device)\n",
        "pos = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
        "div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000) / d_model))\n",
        "pe[:,0::2] = torch.sin(pos*div)\n",
        "pe[:,1::2] = torch.cos(pos*div)\n",
        "pe = pe.unsqueeze(0)\n",
        "\n",
        "x = x + pe[:, :x.shape[1],:]\n",
        "print(f\"after positional embedding: {x.size()}\\n\")\n",
        "\n",
        "# when training...\n",
        "\n",
        "print(\"TRAINING PROCESS\")\n",
        "dataiter = iter(train_loader)\n",
        "batch = next(dataiter)\n",
        "\n",
        "x = batch['source_ids'].to(device)\n",
        "print(f\"source size: {x.size()}\\n\")\n",
        "\n",
        "embedding = nn.Embedding(vocab_size, d_model).to(device)\n",
        "x = embedding(x) * (d_model ** 0.5)\n",
        "print(f\"after embedding: {x.size()}\\n\")\n",
        "\n",
        "pe = torch.zeros(seq_len, d_model).to(device)\n",
        "pos = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
        "div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000) / d_model))\n",
        "pe[:,0::2] = torch.sin(pos*div)\n",
        "pe[:,1::2] = torch.cos(pos*div)\n",
        "pe = pe.unsqueeze(0)\n",
        "\n",
        "x = x + pe[:, :x.shape[1],:]\n",
        "print(f\"after positional embedding: {x.size()}\\n\")\n",
        "\n",
        "\n",
        "# when validating...\n",
        "\n",
        "print(\"VALIDATING PROCESS\")\n",
        "dataiter = iter(val_loader)\n",
        "batch = next(dataiter)\n",
        "\n",
        "x = batch['source_ids'].to(device)\n",
        "print(f\"source size: {x.size()}\\n\")\n",
        "\n",
        "embedding = nn.Embedding(vocab_size, d_model).to(device)\n",
        "x = embedding(x) * (d_model ** 0.5)\n",
        "print(f\"after embedding: {x.size()}\\n\")\n",
        "\n",
        "pe = torch.zeros(seq_len, d_model).to(device)\n",
        "pos = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
        "div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000) / d_model))\n",
        "pe[:,0::2] = torch.sin(pos*div)\n",
        "pe[:,1::2] = torch.cos(pos*div)\n",
        "pe = pe.unsqueeze(0)\n",
        "\n",
        "x = x + pe[:, :x.shape[1],:]\n",
        "print(f\"after positional embedding: {x.size()}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnNlqP2H3wtN",
        "outputId": "2c9f741f-bc1c-400b-c086-c8576c892611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source size: torch.Size([1, 1])\n",
            "\n",
            "after embedding: torch.Size([1, 1, 256])\n",
            "\n",
            "after positional embedding: torch.Size([1, 1, 256])\n",
            "\n",
            "TRAINING PROCESS\n",
            "source size: torch.Size([4, 256])\n",
            "\n",
            "after embedding: torch.Size([4, 256, 256])\n",
            "\n",
            "after positional embedding: torch.Size([4, 256, 256])\n",
            "\n",
            "VALIDATING PROCESS\n",
            "source size: torch.Size([1, 256])\n",
            "\n",
            "after embedding: torch.Size([1, 256, 256])\n",
            "\n",
            "after positional embedding: torch.Size([1, 256, 256])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 256\n",
        "seq_len = 256\n",
        "d_k = d_model // h\n",
        "\n",
        "ln1 = nn.LayerNorm(d_model).to(device)\n",
        "\n",
        "x = torch.empty(1,5).fill_(101).type_as(source).to(device)\n",
        "print(f\"source size: {x.size()}\\n\")\n",
        "\n",
        "\n",
        "# Positional Embedding for source and target\n",
        "tgt_embedding = InputEmbedding(vocab_size, d_model).to(device)\n",
        "tgt_pos_embedding = PositionalEmbedding(d_model, seq_len).to(device)\n",
        "\n",
        "\n",
        "x = tgt_embedding(x)\n",
        "print(f\"after input embedding: {x.size()}\\n\")\n",
        "x = tgt_pos_embedding(x)\n",
        "print(f\"after positional embedding: {x.size()}\\n\")\n",
        "\n",
        "\n",
        "SHA_W_q = nn.Linear(d_model, d_model, bias=False).to(device)\n",
        "SHA_W_k = nn.Linear(d_model, d_model, bias=False).to(device)\n",
        "SHA_W_v = nn.Linear(d_model, d_model, bias=False).to(device)\n",
        "SHA_W_o = nn.Linear(d_model, d_model, bias=False).to(device)\n",
        "\n",
        "query = SHA_W_q(x)\n",
        "key = SHA_W_k(x)\n",
        "value = SHA_W_v(x)\n",
        "print(f\"query size: {query.size()}\\n\")\n",
        "print(f\"key size: {key.size()}\\n\")\n",
        "print(f\"value size: {value.size()}\\n\")\n",
        "\n",
        "q_B, q_seq_len, _ = query.size()\n",
        "k_B, k_seq_len, _ = key.size()\n",
        "v_B, v_seq_len, _ = value.size()\n",
        "\n",
        "query = query.view(q_B, q_seq_len, h, d_k)\n",
        "key = key.view(k_B, k_seq_len, h, d_k)\n",
        "value = value.view(v_B, v_seq_len, h, d_k)\n",
        "print(f\"query size: {query.size()}\\n\")\n",
        "print(f\"key size: {key.size()}\\n\")\n",
        "print(f\"value size: {value.size()}\\n\")\n",
        "\n",
        "# size: (Batch, Seq_len, h, d_model // h) -> (B*h, seq_len, d_model//h)\n",
        "query = query.transpose(1,2).contiguous().view(q_B * h, q_seq_len, d_k)\n",
        "key = key.transpose(1,2).contiguous().view(k_B * h, k_seq_len, d_k)\n",
        "value = value.transpose(1,2).contiguous().view(v_B * h, v_seq_len, d_k)\n",
        "\n",
        "print(f\"query size: {query.size()}\\n\")\n",
        "print(f\"key size: {key.size()}\\n\")\n",
        "print(f\"value size: {value.size()}\\n\")\n",
        "\n",
        "\n",
        "W = query @ key.transpose(1, 2) / math.sqrt(d_k)\n",
        "# print(f\"W before masking:\\n {W}\\n\")\n",
        "print(f\"W before masking size: {W.size()}\\n\")\n",
        "\n",
        "decoder_mask = torch.tril(torch.ones(h, x.size(1), x.size(1))).unsqueeze(0).type(torch.int).to(device)\n",
        "print(f\"Decoder mask size: {decoder_mask.size()}\\n\")\n",
        "decoder_mask = decoder_mask.view(q_B * h, q_seq_len, q_seq_len)\n",
        "print(f\"Mask:\\n {decoder_mask}\\n\")\n",
        "print(f\"Decoder mask size: {decoder_mask.size()}\\n\")\n",
        "W = W.masked_fill_(decoder_mask == 0, -1e9)\n",
        "print(f\"W after masking:\\n {W}\\n\")\n",
        "\n",
        "\n",
        "W = W.softmax(dim = -1)\n",
        "out = W @ value\n",
        "print(f\"out size: {out.size()}\\n\")\n",
        "B, seq_len, d_k = out.size()\n",
        "B = B //h\n",
        "out = out.view(B, h, seq_len, d_k)\n",
        "out = out.transpose(1, 2).contiguous().view(B, seq_len, h * d_k)\n",
        "print(f\"out size: {out.size()}\\n\")\n",
        "\n",
        "sha_out = SHA_W_o(out)\n",
        "print(f\"Self Head Attention out size: {sha_out.size()}\\n\")\n",
        "\n",
        "x = x + sha_out\n",
        "x = ln1(x)\n",
        "print(f\"x size: {x.size()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdLVNmEmhtf4",
        "outputId": "2a067d2b-e017-44a6-ff12-06074040deb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source size: torch.Size([1, 5])\n",
            "\n",
            "after input embedding: torch.Size([1, 5, 256])\n",
            "\n",
            "after positional embedding: torch.Size([1, 5, 256])\n",
            "\n",
            "query size: torch.Size([1, 5, 256])\n",
            "\n",
            "key size: torch.Size([1, 5, 256])\n",
            "\n",
            "value size: torch.Size([1, 5, 256])\n",
            "\n",
            "query size: torch.Size([1, 5, 2, 128])\n",
            "\n",
            "key size: torch.Size([1, 5, 2, 128])\n",
            "\n",
            "value size: torch.Size([1, 5, 2, 128])\n",
            "\n",
            "query size: torch.Size([2, 5, 128])\n",
            "\n",
            "key size: torch.Size([2, 5, 128])\n",
            "\n",
            "value size: torch.Size([2, 5, 128])\n",
            "\n",
            "W before masking size: torch.Size([2, 5, 5])\n",
            "\n",
            "Decoder mask size: torch.Size([1, 2, 5, 5])\n",
            "\n",
            "Mask:\n",
            " tensor([[[1, 0, 0, 0, 0],\n",
            "         [1, 1, 0, 0, 0],\n",
            "         [1, 1, 1, 0, 0],\n",
            "         [1, 1, 1, 1, 0],\n",
            "         [1, 1, 1, 1, 1]],\n",
            "\n",
            "        [[1, 0, 0, 0, 0],\n",
            "         [1, 1, 0, 0, 0],\n",
            "         [1, 1, 1, 0, 0],\n",
            "         [1, 1, 1, 1, 0],\n",
            "         [1, 1, 1, 1, 1]]], device='cuda:0', dtype=torch.int32)\n",
            "\n",
            "Decoder mask size: torch.Size([2, 5, 5])\n",
            "\n",
            "W after masking:\n",
            " tensor([[[ 5.4661e+01, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "         [ 5.3682e+01,  5.3385e+01, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "         [ 5.3557e+01,  5.3258e+01,  5.3715e+01, -1.0000e+09, -1.0000e+09],\n",
            "         [ 5.4221e+01,  5.3934e+01,  5.4394e+01,  5.6046e+01, -1.0000e+09],\n",
            "         [ 5.5099e+01,  5.4832e+01,  5.5297e+01,  5.6939e+01,  5.9428e+01]],\n",
            "\n",
            "        [[ 4.0449e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "         [ 3.4543e+00,  4.4961e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "         [ 3.5751e+00,  4.6123e+00,  4.6141e+00, -1.0000e+09, -1.0000e+09],\n",
            "         [ 4.8086e+00,  5.8444e+00,  5.8347e+00,  5.1910e+00, -1.0000e+09],\n",
            "         [ 6.5781e+00,  7.6137e+00,  7.5921e+00,  6.9306e+00,  6.1889e+00]]],\n",
            "       device='cuda:0', grad_fn=<MaskedFillBackward0>)\n",
            "\n",
            "out size: torch.Size([2, 5, 128])\n",
            "\n",
            "out size: torch.Size([1, 5, 256])\n",
            "\n",
            "Self Head Attention out size: torch.Size([1, 5, 256])\n",
            "\n",
            "x size: torch.Size([1, 5, 256])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CHECK CROSS HEAD ATTENTION"
      ],
      "metadata": {
        "id": "IwWFddK25fyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Source id size: torch.Size([1, 256])\n",
        "# Source mask size: torch.Size([1, 4, 256, 256])\n",
        "\n",
        "# Decoder input size: torch.Size([1, 1])\n",
        "# Encoder output size: torch.Size([1, 256, 256])\n",
        "\n",
        "ln2 = nn.LayerNorm(d_model).to(device)\n",
        "\n",
        "# Cross-Head Attention\n",
        "# self.CrossHeadAttention(x, encoder_out, encoder_out, src_mask)\n",
        "CHA_W_q = nn.Linear(d_model, d_model, bias=False).to(device)\n",
        "CHA_W_k = nn.Linear(d_model, d_model, bias=False).to(device)\n",
        "CHA_W_v = nn.Linear(d_model, d_model, bias=False).to(device)\n",
        "CHA_W_o = nn.Linear(d_model, d_model, bias=False).to(device)\n",
        "\n",
        "query = CHA_W_q(x)\n",
        "key = CHA_W_k(encoder_out)\n",
        "value = CHA_W_v(encoder_out)\n",
        "\n",
        "print(f\"query size: {query.size()}\\n\")\n",
        "print(f\"key size: {key.size()}\\n\")\n",
        "print(f\"value size: {value.size()}\\n\")\n",
        "\n",
        "q_B, q_seq_len, _ = query.size()\n",
        "k_B, k_seq_len, _ = key.size()\n",
        "v_B, v_seq_len, _ = value.size()\n",
        "# size: (Batch, Seq_len, d_model) -> (Batch, Seq_len, h, d_model // h)\n",
        "query = query.view(q_B, q_seq_len, h, d_k)\n",
        "key = key.view(k_B, k_seq_len, h, d_k)\n",
        "value = value.view(v_B, v_seq_len, h, d_k)\n",
        "print(f\"query size: {query.size()}\\n\")\n",
        "print(f\"key size: {key.size()}\\n\")\n",
        "print(f\"value size: {value.size()}\\n\")\n",
        "\n",
        "# size: (Batch, Seq_len, h, d_model // h) -> (B*h, seq_len, d_model//h)\n",
        "query = query.transpose(1,2).contiguous().view(q_B * h, q_seq_len, d_k)\n",
        "key = key.transpose(1,2).contiguous().view(k_B * h, k_seq_len, d_k)\n",
        "value = value.transpose(1,2).contiguous().view(v_B * h, v_seq_len, d_k)\n",
        "\n",
        "print(f\"query size: {query.size()}\\n\")\n",
        "print(f\"key size: {key.size()}\\n\")\n",
        "print(f\"value size: {value.size()}\\n\")\n",
        "\n",
        "W = query @ key.transpose(1, 2) / math.sqrt(d_k)\n",
        "print(f\"W before masking size: {W.size()}\\n\")\n",
        "\n",
        "src_mask = source_mask.view(k_B * h, k_seq_len, k_seq_len)\n",
        "src_mask = src_mask[:,:q_seq_len,:]\n",
        "print(f\"Mask:\\n {src_mask}\\n\")\n",
        "print(f\"Source mask size: {src_mask[:,:q_seq_len,:].size()}\\n\")\n",
        "W = W.masked_fill_(src_mask == 0, -1e9)\n",
        "print(f\"W after masking size:\\n {W.size()}\\n\")\n",
        "\n",
        "W = W.softmax(dim = -1)\n",
        "out = W @ value\n",
        "print(f\"out size: {out.size()}\\n\")\n",
        "B, seq_len, d_k = out.size()\n",
        "B = B //h\n",
        "out = out.view(B, h, seq_len, d_k)\n",
        "out = out.transpose(1, 2).contiguous().view(B, seq_len, h * d_k)\n",
        "print(f\"out size: {out.size()}\\n\")\n",
        "\n",
        "cha_out = CHA_W_o(out)\n",
        "print(f\"Cross Head Attention out size: {cha_out.size()}\\n\")\n",
        "\n",
        "x = x + cha_out\n",
        "x = ln2(x)\n",
        "print(f\"x size: {x.size()}\\n\")\n",
        "\n",
        "# # x = self.ln_2(x)\n",
        "# # x = x + self.FeedForward(x)\n",
        "# # x = self.ln_3(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoFvc3BuwSTz",
        "outputId": "c1887fc9-c482-45b3-cdfa-d7a0b56d9a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query size: torch.Size([1, 2, 256])\n",
            "\n",
            "key size: torch.Size([1, 256, 256])\n",
            "\n",
            "value size: torch.Size([1, 256, 256])\n",
            "\n",
            "query size: torch.Size([1, 2, 2, 128])\n",
            "\n",
            "key size: torch.Size([1, 256, 2, 128])\n",
            "\n",
            "value size: torch.Size([1, 256, 2, 128])\n",
            "\n",
            "query size: torch.Size([2, 2, 128])\n",
            "\n",
            "key size: torch.Size([2, 256, 128])\n",
            "\n",
            "value size: torch.Size([2, 256, 128])\n",
            "\n",
            "W before masking size: torch.Size([2, 2, 256])\n",
            "\n",
            "Mask:\n",
            " tensor([[[1, 1, 1,  ..., 0, 0, 0],\n",
            "         [1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 1, 1,  ..., 0, 0, 0],\n",
            "         [1, 1, 1,  ..., 0, 0, 0]]], device='cuda:0')\n",
            "\n",
            "Source mask size: torch.Size([2, 2, 256])\n",
            "\n",
            "W after masking size:\n",
            " torch.Size([2, 2, 256])\n",
            "\n",
            "out size: torch.Size([2, 2, 128])\n",
            "\n",
            "out size: torch.Size([1, 2, 256])\n",
            "\n",
            "Cross Head Attention out size: torch.Size([1, 2, 256])\n",
            "\n",
            "x size: torch.Size([1, 2, 256])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FEEDFORWARD"
      ],
      "metadata": {
        "id": "AcSxoavD6Iiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ff = FeedForward(config).to(device)\n",
        "ln3 = nn.LayerNorm(d_model).to(device)\n",
        "\n",
        "x = x + ff(x)\n",
        "x = ln3(x)\n",
        "print(f\"x size: {x.size()}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb688vZm52IE",
        "outputId": "e2d6d1cb-6ffe-4170-a19c-ce6ac1c5fca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x size: torch.Size([1, 2, 256])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CHECK FOR TRAINING"
      ],
      "metadata": {
        "id": "Ie0YiSOl6ggN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"TRAINING PROCESS\")\n",
        "dataiter = iter(train_loader)\n",
        "batch = next(dataiter)\n",
        "\n",
        "d_model = 256\n",
        "seq_len = 256\n",
        "d_k = d_model // h\n",
        "\n",
        "ln1 = nn.LayerNorm(d_model).to(device)\n",
        "\n",
        "source = batch['source_ids'].to(device)\n",
        "target = batch['target_ids'].to(device)\n",
        "src_mask = batch['source_masks'].to(device)\n",
        "tgt_mask = batch['target_masks'].to(device)\n",
        "\n",
        "# Positional Embedding for source and target\n",
        "tgt_embedding = InputEmbedding(vocab_size, d_model).to(device)\n",
        "tgt_pos_embedding = PositionalEmbedding(d_model, seq_len).to(device)\n",
        "\n",
        "\n",
        "x = tgt_embedding(target)\n",
        "print(f\"after input embedding: {x.size()}\\n\")\n",
        "x = tgt_pos_embedding(x)\n",
        "print(f\"after positional embedding: {x.size()}\\n\")\n",
        "\n",
        "\n",
        "SHA_W_q = nn.Linear(d_model, d_model, bias=False).to(device)\n",
        "SHA_W_k = nn.Linear(d_model, d_model, bias=False).to(device)\n",
        "SHA_W_v = nn.Linear(d_model, d_model, bias=False).to(device)\n",
        "SHA_W_o = nn.Linear(d_model, d_model, bias=False).to(device)\n",
        "\n",
        "query = SHA_W_q(x)\n",
        "key = SHA_W_k(x)\n",
        "value = SHA_W_v(x)\n",
        "print(f\"query size: {query.size()}\\n\")\n",
        "print(f\"key size: {key.size()}\\n\")\n",
        "print(f\"value size: {value.size()}\\n\")\n",
        "\n",
        "q_B, q_seq_len, _ = query.size()\n",
        "k_B, k_seq_len, _ = key.size()\n",
        "v_B, v_seq_len, _ = value.size()\n",
        "\n",
        "query = query.view(q_B, q_seq_len, h, d_k)\n",
        "key = key.view(k_B, k_seq_len, h, d_k)\n",
        "value = value.view(v_B, v_seq_len, h, d_k)\n",
        "print(f\"query size: {query.size()}\\n\")\n",
        "print(f\"key size: {key.size()}\\n\")\n",
        "print(f\"value size: {value.size()}\\n\")\n",
        "\n",
        "# size: (Batch, Seq_len, h, d_model // h) -> (B*h, seq_len, d_model//h)\n",
        "query = query.transpose(1,2).contiguous().view(q_B * h, q_seq_len, d_k)\n",
        "key = key.transpose(1,2).contiguous().view(k_B * h, k_seq_len, d_k)\n",
        "value = value.transpose(1,2).contiguous().view(v_B * h, v_seq_len, d_k)\n",
        "\n",
        "print(f\"query size: {query.size()}\\n\")\n",
        "print(f\"key size: {key.size()}\\n\")\n",
        "print(f\"value size: {value.size()}\\n\")\n",
        "\n",
        "\n",
        "W = query @ key.transpose(1, 2) / math.sqrt(d_k)\n",
        "print(f\"W before masking:\\n {W}\\n\")\n",
        "print(f\"W size: {W.size()}\\n\")\n",
        "\n",
        "print(f\"Mask:\\n {tgt_mask}\\n\")\n",
        "print(f\"Decoder mask size: {tgt_mask.size()}\\n\")\n",
        "tgt_mask = tgt_mask.view(q_B* h, k_seq_len, k_seq_len) # (B, h, Seq_len, Seq_len) => (B * h, Seq_len, Seq_len)\n",
        "\n",
        "W = W.masked_fill_(tgt_mask == 0, -1e9)\n",
        "print(f\"W after masking:\\n {W}\\n\")\n",
        "\n",
        "\n",
        "W = W.softmax(dim = -1)\n",
        "out = W @ value\n",
        "print(f\"out size: {out.size()}\\n\")\n",
        "B, seq_len, d_k = out.size()\n",
        "B = B //h\n",
        "out = out.view(B, h, seq_len, d_k)\n",
        "out = out.transpose(1, 2).contiguous().view(B, seq_len, h * d_k)\n",
        "print(f\"out size: {out.size()}\\n\")\n",
        "\n",
        "sha_out = SHA_W_o(out)\n",
        "print(f\"Self Head Attention out size: {sha_out.size()}\\n\")\n",
        "\n",
        "x = x + sha_out\n",
        "x = ln1(x)\n",
        "print(f\"x size: {x.size()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4reMayX6Lmo",
        "outputId": "372c0bcc-bcfc-4643-f9fa-a2b2040f51bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING PROCESS\n",
            "after input embedding: torch.Size([4, 256, 256])\n",
            "\n",
            "after positional embedding: torch.Size([4, 256, 256])\n",
            "\n",
            "query size: torch.Size([4, 256, 256])\n",
            "\n",
            "key size: torch.Size([4, 256, 256])\n",
            "\n",
            "value size: torch.Size([4, 256, 256])\n",
            "\n",
            "query size: torch.Size([4, 256, 2, 128])\n",
            "\n",
            "key size: torch.Size([4, 256, 2, 128])\n",
            "\n",
            "value size: torch.Size([4, 256, 2, 128])\n",
            "\n",
            "query size: torch.Size([8, 256, 128])\n",
            "\n",
            "key size: torch.Size([8, 256, 128])\n",
            "\n",
            "value size: torch.Size([8, 256, 128])\n",
            "\n",
            "W before masking:\n",
            " tensor([[[  78.6641,  132.3236, -138.1175,  ...,  -15.7316,  -16.5606,\n",
            "           -16.8900],\n",
            "         [  54.0509,   79.4072,   51.2084,  ...,  -52.3254,  -55.0169,\n",
            "           -57.6886],\n",
            "         [  51.9549,  118.6219,  163.1727,  ...,  -63.9407,  -65.0058,\n",
            "           -65.7316],\n",
            "         ...,\n",
            "         [  42.6520,   24.7375,  -61.6832,  ...,  -14.1162,  -15.2030,\n",
            "           -16.4563],\n",
            "         [  42.9732,   23.9359,  -61.8729,  ...,  -13.5574,  -14.6552,\n",
            "           -15.9211],\n",
            "         [  43.3201,   23.4036,  -62.3178,  ...,  -12.6292,  -13.7267,\n",
            "           -14.9978]],\n",
            "\n",
            "        [[-143.9107,   -6.8044,  -11.9729,  ...,  142.1309,  141.8233,\n",
            "           141.3141],\n",
            "         [-200.1457,   -5.8214,  176.2921,  ...,  113.6646,  112.0783,\n",
            "           112.0448],\n",
            "         [ 163.3703,   13.9437,  -42.8567,  ...,  112.0397,  112.2341,\n",
            "           111.3450],\n",
            "         ...,\n",
            "         [  20.2271,   29.9025,   -1.7827,  ...,  -41.7281,  -41.1228,\n",
            "           -41.2597],\n",
            "         [  18.9383,   28.7895,   -1.6725,  ...,  -41.0022,  -40.4113,\n",
            "           -40.5677],\n",
            "         [  18.2494,   28.5366,   -1.3463,  ...,  -42.0847,  -41.5044,\n",
            "           -41.6689]],\n",
            "\n",
            "        [[  78.6641,   15.5963,  -27.6021,  ...,  -15.7316,  -16.5606,\n",
            "           -16.8900],\n",
            "         [ -23.3626,   72.4501,   88.1075,  ...,   16.8566,   17.9637,\n",
            "            19.2964],\n",
            "         [  56.9878,    0.3179,  -96.8785,  ...,  -13.9752,  -14.1019,\n",
            "           -13.4942],\n",
            "         ...,\n",
            "         [  42.6520,   98.9686,  -45.9118,  ...,  -14.1162,  -15.2030,\n",
            "           -16.4563],\n",
            "         [  42.9732,   97.7439,  -47.0072,  ...,  -13.5574,  -14.6552,\n",
            "           -15.9211],\n",
            "         [  43.3201,   96.0330,  -49.2563,  ...,  -12.6292,  -13.7267,\n",
            "           -14.9978]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-143.9107,  -64.1245, -114.0971,  ...,  142.1309,  141.8233,\n",
            "           141.3141],\n",
            "         [-227.6747,   20.8410,  161.5572,  ...,  129.8868,  127.8131,\n",
            "           127.1225],\n",
            "         [  93.5902,  -45.5252,   26.2502,  ...,  -15.3670,  -14.1670,\n",
            "           -13.3565],\n",
            "         ...,\n",
            "         [  20.2271, -189.6929,  -74.8962,  ...,  -41.7281,  -41.1228,\n",
            "           -41.2597],\n",
            "         [  18.9383, -190.1223,  -76.2675,  ...,  -41.0022,  -40.4113,\n",
            "           -40.5677],\n",
            "         [  18.2494, -191.0315,  -77.1236,  ...,  -42.0847,  -41.5044,\n",
            "           -41.6689]],\n",
            "\n",
            "        [[  78.6641,   45.2364,   46.0610,  ...,  -15.7316,  -16.5606,\n",
            "           -16.8900],\n",
            "         [ -14.2305, -177.6313,   50.0429,  ...,   -2.2326,   -2.5683,\n",
            "            -2.0019],\n",
            "         [  18.6698,  287.2241,  166.8527,  ...,    2.7491,    2.5115,\n",
            "             2.3665],\n",
            "         ...,\n",
            "         [  42.6520,  -68.2209,  -66.7391,  ...,  -14.1162,  -15.2030,\n",
            "           -16.4563],\n",
            "         [  42.9732,  -66.9854,  -66.0252,  ...,  -13.5574,  -14.6552,\n",
            "           -15.9211],\n",
            "         [  43.3201,  -64.5207,  -65.0977,  ...,  -12.6292,  -13.7267,\n",
            "           -14.9978]],\n",
            "\n",
            "        [[-143.9107,   -3.9058,   24.0735,  ...,  142.1309,  141.8233,\n",
            "           141.3141],\n",
            "         [-128.9758,  153.8642,  -88.4281,  ...,  104.3457,  105.4114,\n",
            "           105.1028],\n",
            "         [  76.3451,  134.0296,  -49.4820,  ...,   22.0325,   21.9877,\n",
            "            21.2480],\n",
            "         ...,\n",
            "         [  20.2271,   86.9125, -147.2236,  ...,  -41.7281,  -41.1228,\n",
            "           -41.2597],\n",
            "         [  18.9383,   87.3265, -147.0710,  ...,  -41.0022,  -40.4113,\n",
            "           -40.5677],\n",
            "         [  18.2494,   88.1861, -146.6972,  ...,  -42.0847,  -41.5044,\n",
            "           -41.6689]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "W size: torch.Size([8, 256, 256])\n",
            "\n",
            "Mask:\n",
            " tensor([[[[1, 0, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "         [[1, 0, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[1, 0, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "         [[1, 0, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[1, 0, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "         [[1, 0, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0]]],\n",
            "\n",
            "\n",
            "        [[[1, 0, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0]],\n",
            "\n",
            "         [[1, 0, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 0,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          ...,\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0],\n",
            "          [1, 1, 1,  ..., 0, 0, 0]]]], device='cuda:0', dtype=torch.int32)\n",
            "\n",
            "Decoder mask size: torch.Size([4, 2, 256, 256])\n",
            "\n",
            "W after masking:\n",
            " tensor([[[ 7.8664e+01, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 5.4051e+01,  7.9407e+01, -1.0000e+09,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 5.1955e+01,  1.1862e+02,  1.6317e+02,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         ...,\n",
            "         [ 4.2652e+01,  2.4737e+01, -6.1683e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 4.2973e+01,  2.3936e+01, -6.1873e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 4.3320e+01,  2.3404e+01, -6.2318e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "        [[-1.4391e+02, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [-2.0015e+02, -5.8214e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 1.6337e+02,  1.3944e+01, -4.2857e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         ...,\n",
            "         [ 2.0227e+01,  2.9902e+01, -1.7827e+00,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 1.8938e+01,  2.8790e+01, -1.6725e+00,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 1.8249e+01,  2.8537e+01, -1.3463e+00,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "        [[ 7.8664e+01, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [-2.3363e+01,  7.2450e+01, -1.0000e+09,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 5.6988e+01,  3.1790e-01, -9.6879e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         ...,\n",
            "         [ 4.2652e+01,  9.8969e+01, -4.5912e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 4.2973e+01,  9.7744e+01, -4.7007e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 4.3320e+01,  9.6033e+01, -4.9256e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-1.4391e+02, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [-2.2767e+02,  2.0841e+01, -1.0000e+09,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 9.3590e+01, -4.5525e+01,  2.6250e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         ...,\n",
            "         [ 2.0227e+01, -1.8969e+02, -7.4896e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 1.8938e+01, -1.9012e+02, -7.6267e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 1.8249e+01, -1.9103e+02, -7.7124e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "        [[ 7.8664e+01, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [-1.4231e+01, -1.7763e+02, -1.0000e+09,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 1.8670e+01,  2.8722e+02,  1.6685e+02,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         ...,\n",
            "         [ 4.2652e+01, -6.8221e+01, -6.6739e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 4.2973e+01, -6.6985e+01, -6.6025e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 4.3320e+01, -6.4521e+01, -6.5098e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09]],\n",
            "\n",
            "        [[-1.4391e+02, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [-1.2898e+02,  1.5386e+02, -1.0000e+09,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 7.6345e+01,  1.3403e+02, -4.9482e+01,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         ...,\n",
            "         [ 2.0227e+01,  8.6913e+01, -1.4722e+02,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 1.8938e+01,  8.7327e+01, -1.4707e+02,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09],\n",
            "         [ 1.8249e+01,  8.8186e+01, -1.4670e+02,  ..., -1.0000e+09,\n",
            "          -1.0000e+09, -1.0000e+09]]], device='cuda:0',\n",
            "       grad_fn=<MaskedFillBackward0>)\n",
            "\n",
            "out size: torch.Size([8, 256, 128])\n",
            "\n",
            "out size: torch.Size([4, 256, 256])\n",
            "\n",
            "Self Head Attention out size: torch.Size([4, 256, 256])\n",
            "\n",
            "x size: torch.Size([4, 256, 256])\n",
            "\n"
          ]
        }
      ]
    }
  ]
}